{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spark session libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "## Required for parsing the file as csv\n",
    "import csv\n",
    "from io import StringIO\n",
    "from itertools import islice, repeat\n",
    "\n",
    "## For preprocessing\n",
    "from re import search, split, sub, compile as comp\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "## For Plots\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib import cm, colors\n",
    "\n",
    "\n",
    "## for RF model\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import RandomForestRegressionModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import types\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from numpy import allclose\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n",
      "local[*,4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\util.py:141: UserWarning: Currently, 'setLocalProperty' (set to local properties) with multiple threads does not properly work. \n",
      "Internally threads on PVM and JVM are not synced, and JVM thread can be reused for multiple threads on PVM, which fails to isolate local properties for each thread on PVM. \n",
      "To work around this, you can set PYSPARK_PIN_THREAD to true (see SPARK-22340). However, note that it cannot inherit the local properties from the parent thread although it isolates each thread on PVM and JVM with its own local properties. \n",
      "To work around this, you should manually copy and set the local properties from the parent thread to the child thread when you create another thread.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MSI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*,4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SDDM</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*,4] appName=SDDM>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(appName=\"SDDM\", master='local[*,4]')\n",
    "sc.setLocalProperty(\"spark.scheduler.pool\", \"pool1\")\n",
    "#ss = SparkSession.builder.appName('SDDM_2').getOrCreate()\n",
    "print(sc.pythonVer)\n",
    "print (sc.master)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"64g\") \\\n",
    "    .appName('SDDM2') \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"32g\")\\\n",
    "    .config(\"spark.executor.memory\", \"64g\")\\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCSV(csvRow) :\n",
    "    '''Parses a row into a list of elements '''\n",
    "    data = StringIO(csvRow)\n",
    "    dataReader = csv.reader(data, lineterminator = '')\n",
    "    return(next(dataReader))\n",
    "\n",
    "def readFileAsCSV(session, filepath):\n",
    "    '''Reads a files as text file and then parses each row and returns a list of list: \n",
    "        [[Row]\n",
    "         [Row]\n",
    "         [Row]]\n",
    "     '''\n",
    "    try:\n",
    "        data = session.textFile(name = str(filepath))\n",
    "        data = data.map(parseCSV)\n",
    "    except:\n",
    "        print('Failed to read the file!')\n",
    "        data = []\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tickTime(x, ind):\n",
    "    '''Extracts the month and year from the issue date'''\n",
    "    try:\n",
    "        m = int(x[ind][0:2])\n",
    "        y = int(x[ind][6:10])\n",
    "    except:\n",
    "        m = '0'\n",
    "        y = '0'    \n",
    "    x.append(str(m))\n",
    "    x.append(str(y))\n",
    "    return x\n",
    "\n",
    "def street_preprocess(x, ind):\n",
    "    '''Preprocess the street names'''\n",
    "    s = x[ind]\n",
    "    s = s.replace('AVENUE','AVE').replace('STREET','ST').replace('BLVD','BL')\n",
    "    s = s.replace('\\sEAST\\s',' E ').replace('\\sWEST\\s',' W ').replace('\\sNORTH\\s',' N ').replace('\\sSOUTH\\s',' S ')\n",
    "    s = s.replace('\\sROAD\\s',' RD ').replace('\\sEXPY\\s','EXWY').replace('\\sPARKWY\\s','PKWY').replace('\\sISLAND\\s','ISL')\n",
    "    s = s.replace('\\sFIRST\\s','1').replace('\\sSECOND\\s','2').replace('\\sTHRID\\s','3')\n",
    "    s = s.replace('\\sFOURTH\\s','4').replace('\\sFIVETH\\s','5').replace('\\sSIXTH\\s','6')\n",
    "    s = s.replace('\\sSEVENTH\\s','7').replace('\\sEIGHTH\\s','8').replace('\\sNINETH\\s','9').replace('\\sTENTH\\s','10')\n",
    "    s = s.split()\n",
    "    result = [x if not search(r'\\d', x) else sub('[^0-9]','', x) for x in s]\n",
    "    result = ' '.join(result)\n",
    "    x[ind] = result.lower()\n",
    "    return x\n",
    "\n",
    "def rState(x, ind):\n",
    "    if x[ind] == 'NY':\n",
    "        x.append('0')\n",
    "    else:\n",
    "        x.append('1')\n",
    "    return x\n",
    "\n",
    "def violationType(x, ind):\n",
    "    mydict = {\"Misc\":[35,41,90,91,94],\n",
    "                        \"No Parking\":[20,21,23,24,27],\n",
    "                        \"No Standing\":[3,4,5,6,8,10,11,12,13,14,15,16,17,18,19,22,25,26,30,31,40,44,54,57,58,63,64,77,78,81,89,92],\n",
    "                        \"Permit/Doc Issue\":[1,2,29,70,71,72,73,76,80,83,87,88,93,97],\n",
    "                        \"Plate Issues\":[74,75,82],\n",
    "                        \"Obstructing Path\":[7,9,36,45,46,47,48,49,50,51,52,53,55,56,59,60,61,62,66,67,68,79,84,96,98],\n",
    "                        \"Overtime\":[28,32,33,34,37,38,39,42,43,65,69,85,86]\n",
    "                        }\n",
    "    label = ''\n",
    "    try:\n",
    "        for key, value in mydict.items():\n",
    "             for y in value:\n",
    "                    if y == int(x[ind]):\n",
    "                        label = key\n",
    "    except: \n",
    "        label = ''\n",
    "    newLabs = {0:'',\n",
    "               1:\"Misc\",\n",
    "               2:\"No Parking\",\n",
    "               3:\"No Standing\",\n",
    "               4:\"Permit/Doc Issue\",\n",
    "               5:\"Plate Issues\",\n",
    "               6:\"Obstructing Path\",\n",
    "               7:\"Overtime\"}\n",
    "    x.append(str(list(newLabs.keys())[list(newLabs.values()).index(label)]))\n",
    "    x[ind] = label\n",
    "    return x\n",
    "    \n",
    "def sH(x, ind):\n",
    "    ''' Extracts the street number and house number from House number column\n",
    "        Some house numbers are: 123-34, 45-56 and some are 34, 45 etc\n",
    "    '''\n",
    "    house_num = x[ind]\n",
    "    try:\n",
    "        if house_num == '':\n",
    "            s = '0'\n",
    "            h = '0'\n",
    "        else:\n",
    "            cond = '-' in house_num\n",
    "            if cond:\n",
    "                s, h = house_num.split('-')\n",
    "            else:\n",
    "                s = int(house_num)\n",
    "                h = '0'\n",
    "    except:\n",
    "        s = '0'\n",
    "        h = '0'\n",
    "    x.append(str(s))\n",
    "    x.append(str(h))\n",
    "    return x\n",
    "    \n",
    "def preprocessedCSV(session, filepath):\n",
    "    '''\n",
    "    Reads the csv files, and then converts Issue date to date and month\n",
    "    '''\n",
    "    data = readFileAsCSV(session, filepath)\n",
    "    header = data.take(1)[0]\n",
    "    data = data.map(lambda x: [x[0], x[2], x[3], x[4], x[5], x[6], x[7], x[19], x[23], x[24]])\n",
    "    header = data.take(1)[0]\n",
    "    #print(header)\n",
    "    ## Extracting the month and year\n",
    "    data = data.map(lambda x: tickTime(x, header.index('Issue Date')))\n",
    "    header.append('Issue Month')\n",
    "    header.append('Issue Year')\n",
    "    \n",
    "    ## Removing the header line\n",
    "    data = data.mapPartitionsWithIndex(lambda idx, it: islice(it, 1, None) if idx == 0 else it)\n",
    "    ## Preprocessing the street names\n",
    "    data = data.map(lambda x: street_preprocess(x, header.index('Street Name')))    \n",
    "    ## Extracts the street and house number\n",
    "    data = data.map(lambda x: sH(x, header.index('House Number')))\n",
    "    header.append('Street')\n",
    "    header.append('House')\n",
    "    data = data.map(lambda x: rState(x, header.index('Registration State')))\n",
    "    header.append('RState')\n",
    "    data = data.map(lambda x: violationType(x, header.index('Violation Code')))\n",
    "    header.append('VType')\n",
    "    return data, header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate file processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streetHouse(x):\n",
    "    '''\n",
    "        Extracts the street and house number ranges for a street name and coordinate\n",
    "    '''\n",
    "    house_num = x[0]\n",
    "    try:\n",
    "        if house_num == '':\n",
    "            l_s_min = '0'\n",
    "            l_s_max = '0'\n",
    "            r_s_min = '0'\n",
    "            r_s_max = '0'\n",
    "\n",
    "            h_l_min = '0'\n",
    "            h_l_max = '0'\n",
    "            h_r_min = '0'\n",
    "            h_r_max = '0'\n",
    "        else:\n",
    "            cond = '-' in house_num\n",
    "            if cond:\n",
    "                l_s_min, h_l_min = x[0].split('-')\n",
    "                l_s_max, h_l_max = x[1].split('-')\n",
    "                r_s_min, h_r_min = x[4].split('-')\n",
    "                r_s_max, h_r_max = x[5].split('-')\n",
    "            else:\n",
    "                l_s_min = int(x[0])\n",
    "                l_s_max = int(x[1])\n",
    "                r_s_min = int(x[4])\n",
    "                r_s_max = int(x[5])\n",
    "                h_l_min = '0'\n",
    "                h_l_max = '0'\n",
    "                h_r_min = '0'\n",
    "                h_r_max = '0'\n",
    "\n",
    "    except:\n",
    "        l_s_min = '0'\n",
    "        l_s_max = '0'\n",
    "        r_s_min = '0'\n",
    "        r_s_max = '0'\n",
    "        h_l_min = '0'\n",
    "        h_l_max = '0'\n",
    "        h_r_min = '0'\n",
    "        h_r_max = '0'\n",
    "        \n",
    "    x.extend([l_s_min, l_s_max, r_s_min, r_s_max, h_l_min, h_l_max, h_r_min, h_r_max])\n",
    "    return x\n",
    "\n",
    "def geoms(x, ind):\n",
    "    '''Extracting one single latitute and longitude values from the geometry '''\n",
    "    coords = x[ind]\n",
    "    try: \n",
    "        coords = coords.replace('MULTILINESTRING ', '').replace('(','').replace(')', '').split(', ')\n",
    "        coords = [i.split(' ') for i in coords]\n",
    "        coords = [[float(j), float(k)] for j,k in coords]\n",
    "        lon = str(median([j for j,k in coords ]))\n",
    "        lat = str(median([k for j,k in coords ]))\n",
    "    except:\n",
    "        lon = 'NA'\n",
    "        lat = 'NA'\n",
    "    x.append(lon)\n",
    "    x.append(lat)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def createCoordsFiles(session, filepath):\n",
    "    '''Reading the centerline data set and returns a preprocessed RDD'''\n",
    "    coords = readFileAsCSV(session, filepath) \n",
    "    ## Removing the first line\n",
    "    coords = coords.map(lambda x: [x[0],x[1],x[28],x[3],x[4],x[5]])\n",
    "    ## Getting the header\n",
    "    coords_header = coords.take(1)[0]\n",
    "    coords = coords.mapPartitionsWithIndex(lambda idx, it: islice(it, 1, None) if idx == 0 else it)\n",
    "    ## Preprocessing the street names\n",
    "    coords = coords.map(lambda x: street_preprocess(x, coords_header.index('FULL_STREE'))) \n",
    "    ## Finding the street numbers and house number limits\n",
    "    coords = coords.map(streetHouse)\n",
    "    coords = coords.map(lambda x: geoms(x, coords_header.index('the_geom')))\n",
    "    ## Extracting the required columns\n",
    "    #coords = coords.map(lambda x: [x[2],x[6],x[7],x[8],x[9], x[10], x[11]])\n",
    "    coords_header.extend(['L_S_min', 'L_S_max', 'R_S_min', 'R_S_max', 'L_H_min', 'L_H_max', 'R_H_min', 'R_H_max', 'lon', 'lat'] )\n",
    "    return coords, coords_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match the ticket to their respectve coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchstreet(t, c):\n",
    "    '''\n",
    "    Based on the street and house number in tickets dataframe finds the coordintae value in centerline dataframe\n",
    "    and merges the coordinate value to it.\n",
    "    '''\n",
    "    ## Making the columns integers for comparision\n",
    "    t =  t.withColumn(\"Issue_Month\", t[\"Issue_Month\"].cast('integer'))\n",
    "    t =  t.withColumn(\"Issue_Year\", t[\"Issue_Year\"].cast('integer'))\n",
    "    t =  t.withColumn(\"Street\", t[\"Street\"].cast('integer'))\n",
    "    t =  t.withColumn(\"House\", t[\"House\"].cast('integer'))\n",
    "    t =  t.withColumn(\"RState\", t[\"RState\"].cast('integer'))\n",
    "    t =  t.withColumn(\"VType\", t[\"VType\"].cast('integer'))\n",
    "    t =  t.withColumn(\"Ids\", monotonically_increasing_id())\n",
    "    t =  t.withColumn(\"Ids\", t[\"Ids\"].cast('string'))\n",
    "    \n",
    "    c = c.select('FULL_STREE', c.L_S_min.cast('integer'),c.L_S_max.cast('integer'),\\\n",
    "                 c.R_S_min.cast('integer'),c.R_S_max.cast('integer'),\\\n",
    "                 c.L_H_min.cast('integer'),c.L_H_max.cast('integer'),\\\n",
    "                 c.R_H_min.cast('integer'),c.R_H_max.cast('integer'),\\\n",
    "                 c.lon.cast('float'),c.lat.cast('float'))\n",
    "    ## performs inner join on the tickets. \n",
    "    merged = t.join(c, [t.Street_Name == c.FULL_STREE,\\\n",
    "                        (t.Street>=c.L_S_min)  | (t.Street>=c.R_S_min),\\\n",
    "                        (t.Street<=c.L_S_max)  | (t.Street<=c.R_S_max),\\\n",
    "                        (t.House >=c.L_H_min)  | (t.House >=c.R_H_min),\\\n",
    "                        (t.House <= c.L_H_max) | (t.House <= c.R_H_max)],'inner').select('Ids', 'Summons_Number', 'Registration_State', 'Plate_Type', 'Issue_Date', 'Violation_Code', 'Vehicle_Body_Type', 'Vehicle_Make', 'House_Number', 'Street_Name', 'Issue_Month', 'Issue_Year', 'Violation_Time', 'Street', 'House', 'RState', 'VType', 'lon', 'lat')\n",
    "    \n",
    "    return merged.dropDuplicates(subset=['Ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(sc, filepath, filename, year):\n",
    "    '''Reads each file in a loop and returns a list of RDDs'''\n",
    "    tickets = []\n",
    "    for yr in year:\n",
    "        filelocation = str(filepath)+str(filename)+str(yr)+\".csv\"\n",
    "        print(filelocation)\n",
    "        parking_data, header = preprocessedCSV(sc, filelocation)\n",
    "        tickets.append(parking_data)\n",
    "    return tickets, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(data, Val, Key):\n",
    "    pairs = data.map(lambda x: (x[Key], x[Val]))\n",
    "    return pairs.groupByKey().collect()\n",
    "\n",
    "def group_data_toList(y, groupby):\n",
    "    '''\n",
    "    Input:\n",
    "        - y: Grouped pyspark data returned from group_data function\n",
    "        - groupby: Column name to remove an extra element\n",
    "    '''\n",
    "    lab = list(map(lambda x:x[0], y))\n",
    "    val = list(map(lambda x:len(x[1]), y))\n",
    "    try:\n",
    "        kick = lab.index(groupby)\n",
    "        lab.pop(kick)\n",
    "        val.pop(kick)\n",
    "    except:\n",
    "        0\n",
    "    if groupby=='Issue Month' or groupby == 'Violation Code':\n",
    "        lab = list(map(lambda x: int(x), lab))\n",
    "    return [lab,val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, header, data, year, groupby, pt, plot_data):\n",
    "    '''\n",
    "    Input:\n",
    "        - data: PySpark parsed CSV\n",
    "        - groupby: Column name for grouping the data \n",
    "        - pt: Plot type\n",
    "        - plot data: Variables required for bar plot\n",
    "        \n",
    "    Output: \n",
    "        - Plot\n",
    "    '''\n",
    "    if pt=='bar':\n",
    "        col, val, axis_labels, legend_labels = plot_data\n",
    "        \n",
    "        cat_index = header.index(col)\n",
    "        \n",
    "        cat1 = data.filter(lambda x: x[cat_index]==val)\n",
    "        cat2 = data.filter(lambda x: x[cat_index]!=val)                   \n",
    "\n",
    "        groupby_index = data.take(1)[0].index(groupby)\n",
    "        count_column = data.take(1)[0].index('Summons Number')\n",
    "        \n",
    "        cat1 = group_data_toList(group_data(cat1 , Val=count_column, Key=groupby_index), groupby)\n",
    "        cat2 = group_data_toList(group_data(cat2 , Val=count_column, Key=groupby_index), groupby)\n",
    "            \n",
    "        ## plotting the graph\n",
    "        ax.bar(cat1[0], cat1[1], width = 0.5, label=legend_labels[0]) \n",
    "        ax.bar(cat2[0], cat2[1], width = 0.5, label=legend_labels[1])\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.set_xlabel(groupby, fontsize=18)\n",
    "        ax.set_ylabel('Number of tickets', fontsize=18)\n",
    "        ax.set_title('Parking tickets for the year '+str(year-1), fontsize=22)\n",
    "    if pt == 'pie':\n",
    "        #try:\n",
    "            groupby_index = header.index(groupby)\n",
    "            count_column = header.index('Summons Number')\n",
    "            \n",
    "            label, data = group_data_toList(group_data(data , Val=count_column, Key=groupby_index), groupby)\n",
    "            title = 'Parking ticket '+str(groupby)+' for the year '+str(year-1)\n",
    "            \n",
    "            if groupby == 'Violation Code': \n",
    "                ## Defining the violation code merges as a dictionary\n",
    "                labs = {\"Misc\":[35,41,90,91,94],\n",
    "                        \"No Parking\":[20,21,23,24,27],\n",
    "                        \"No Standing\":[3,4,5,6,8,10,11,12,13,14,15,16,17,18,19,22,25,26,30,31,40,44,54,57,58,63,64,77,78,81,89,92],\n",
    "                        \"Permit/Doc Issue\":[1,2,29,70,71,72,73,76,80,83,87,88,93,97],\n",
    "                        \"Plate Issues\":[74,75,82],\n",
    "                        \"Obstructing Path\":[7,9,36,45,46,47,48,49,50,51,52,53,55,56,59,60,61,62,66,67,68,79,84,96,98],\n",
    "                        \"Overtime\":[28,32,33,34,37,38,39,42,43,65,69,85,86]\n",
    "                        }\n",
    "                ## Count based on the grouping\n",
    "            \n",
    "                temp = defaultdict(list)\n",
    "                for i in range(len(label)):\n",
    "                    for key, val in labs.items():\n",
    "                        if label[i] in val:\n",
    "                            if temp[key] == []:\n",
    "                                temp[key] = 0\n",
    "                            else:\n",
    "                                temp[key] = temp[key]+data[i]\n",
    "\n",
    "                ## Ordering data based on the dictionary \n",
    "                label, data  = list(), list()\n",
    "                for key in labs.keys():\n",
    "                    label.append(key)\n",
    "                    data.append(temp[key])    \n",
    "\n",
    "            ## Defining color for each category\n",
    "            temp = defaultdict(list)\n",
    "            for l,c in zip(labs,cm.tab20(range(len(labs)))):\n",
    "                temp[l]=c\n",
    "\n",
    "            centre_circle = plt.Circle((0,0),0.85,fc='white') ## radius to make it like a donut\n",
    "            explode = np.full(len(label), 0.04) ## Gaps between the categories\n",
    "\n",
    "            pat = ax.pie(list(map(lambda x: x*100/sum(data), data)), labels=label, textprops={'fontsize': 20}, autopct='%1.1f%%', startangle=90, pctdistance=0.6, explode = explode)\n",
    "            if groupby == 'Violation Code':\n",
    "                for pie_wedge in pat[0]:\n",
    "                    pie_wedge.set_edgecolor('white')\n",
    "                    pie_wedge.set_facecolor(temp[pie_wedge.get_label()]) # Assigning color code for each catergory\n",
    "\n",
    "            ax.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "            ax.set_title(title, fontsize =22, pad=20)\n",
    "            plt.gcf().gca().add_artist(centre_circle)\n",
    "        #except:\n",
    "        #    print('Failed to plot!')        \n",
    "    return ax \n",
    "\n",
    "def EDA(header, tickets, year, groupby, pt, plotdim, plot_data):\n",
    "    fig = plt.figure(figsize=(30, 25))\n",
    "    axs=plt.GridSpec(plotdim[0], plotdim[1], hspace=0.15, wspace=0.1)\n",
    "    for i in range(len(year)):\n",
    "        plot(fig.add_subplot(axs[i]), header, tickets[i], year[i], groupby, pt, plot_data)\n",
    "    plt.savefig('EDA_'+str(groupby)+'_'+str(pt)+'.png',  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final showdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching the ticket with their coordinate values\n",
    "This is done using join method\n",
    "First we convert the `all_tickets` into a dataframe, then we read the cetnerline data set as a dataframe `coord_df` and then using `matchStreet` function we match the coordinates based on the left and right range of street numbers and house numbers based on the street names. \n",
    "Then we select the data which is from the years of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyse(year, filepath, filename, centerline):\n",
    "    ## Returns a list of RDDs, these RDD have data for each year\n",
    "    tickets, header = getData(sc, filepath, filename, year)\n",
    "    ## Reading the centerline data set\n",
    "    coords, c_header = createCoordsFiles(sc, centerline)\n",
    "    coord_df = ss.createDataFrame(coords, schema=c_header)\n",
    "    \n",
    "    tickets_with_coords = []\n",
    "    for i in range(len(tickets)):\n",
    "        ## Converting the RDD list to a pyspark dataframe\n",
    "        tickets_with_coords.append(matchstreet(ss.createDataFrame(tickets[i], schema=[x.replace(' ', '_') for x in header]), coord_df))\n",
    "        ## Keeping the dataset which is from 2015 to 2020\n",
    "        tickets_with_coords[i] = tickets_with_coords[i].filter(F.col('Issue_Year').isin(year))  \n",
    "        #tickets_with_coords[i].rdd.saveAsTextFile(\"PT_\"+str(year[i]))\n",
    "    return tickets, tickets_with_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2015.csv\n",
      "nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\n",
      "nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\n",
      "nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2018.csv\n",
      "nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2019.csv\n",
      "nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2020.csv\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filepath = 'nyc-parking-tickets/'\n",
    "filename = 'Parking_Violations_Issued_-_Fiscal_Year_'\n",
    "centerline = 'Centerline.csv'\n",
    "year = list(range(2015, 2021))\n",
    "\n",
    "tickets, tc_df = Analyse(year, filepath, filename, centerline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA  Skip it for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: Bar plot representing the distribution of tickets over the years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EDA() missing 1 required positional argument: 'plot_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: EDA() missing 1 required positional argument: 'plot_data'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Bar plot\n",
    "category='Registration State'\n",
    "value='NY' \n",
    "axis_labels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']  \n",
    "legend_labels= ['New York', 'Other Cities']\n",
    "plot_data = [category, value, axis_labels, legend_labels]\n",
    "\n",
    "groupby = 'Issue Month'\n",
    "EDA(tickets, year, groupby, 'bar', [int(len(year)/2),2], plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: Pie chart showing the distribution of tickets according to violation code over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'header' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'header' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Pie chart\n",
    "\n",
    "groupby = 'Violation Code'\n",
    "plot_data = []\n",
    "EDA(header, tickets, year, groupby, 'pie', [int(len(year)/2),2], plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 223 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=[\"lat\", \"lon\"], outputCol=\"features\")\n",
    "for i in range(len(year)):\n",
    "    tc_df[i] = vecAssembler.transform(tc_df[i])\n",
    "\n",
    "\n",
    "#vecAssembler = VectorAssembler(inputCols=[\"lat\", \"lon\"], outputCol=\"features\")\n",
    "#t_part1_with_location = vecAssembler.transform(t_part1)\n",
    "#t_part2_with_location = vecAssembler.transform(t_part2)\n",
    "#t_part3_with_location = vecAssembler.transform(t_part3)\n",
    "#t_part4_with_location = vecAssembler.transform(t_part4)\n",
    "#t_part5_with_location = vecAssembler.transform(t_part5)\n",
    "#t_part6_with_location = vecAssembler.transform(t_part6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pyspark.ml.clustering import BisectingKMeans\\nbkm = BisectingKMeans().setK(796).setSeed(1)\\nmodel = bkm.fit(t_part1_with_location.select('features'))\\ntransformed_1 = model.transform(t_part1_with_location)\\nmodel = bkm.fit(t_part2_with_location.select('features'))\\ntransformed_2 = model.transform(t_part2_with_location)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=796, seed=1)  #  clusters here\n",
    "\n",
    "model = kmeans.fit(tc_df[0].select('features'))\n",
    "for i in range(len(year)):\n",
    "    tc_df[i] = model.transform(tc_df[i])\n",
    "\n",
    "\n",
    "#model = kmeans.fit(t_part1_with_location.select('features'))\n",
    "#transformed_1 = model.transform(t_part1_with_location)\n",
    "#transformed_2 = model.transform(t_part2_with_location)\n",
    "#transformed_3 = model.transform(t_part3_with_location)\n",
    "#transformed_4 = model.transform(t_part4_with_location)\n",
    "#transformed_5 = model.transform(t_part5_with_location)\n",
    "#transformed_6 = model.transform(t_part6_with_location)\n",
    "'''\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "bkm = BisectingKMeans().setK(796).setSeed(1)\n",
    "model = bkm.fit(t_part1_with_location.select('features'))\n",
    "transformed_1 = model.transform(t_part1_with_location)\n",
    "model = bkm.fit(t_part2_with_location.select('features'))\n",
    "transformed_2 = model.transform(t_part2_with_location)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctr=[]\n",
    "centers = model.clusterCenters()\n",
    "for center in centers:\n",
    "    ctr.append(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "mc = MarkerCluster()\n",
    "m = folium.Map(\n",
    "    location=[40.767937,-73.982155],\n",
    "    zoom_start=12,)\n",
    "\n",
    "\n",
    "for i in range(len(ctr)):\n",
    "    mc.add_child(folium.Marker(location=[ ctr[i][0],ctr[i][1] ]))\n",
    "\n",
    "\n",
    "m.add_child(mc)\n",
    "m.save('F:/marker_cluster_example_file.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amenity_names = []\n",
    "amenity_count = []\n",
    "import requests, json, time, random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "Amenity_per_location =pd.DataFrame()\n",
    "Amenity_per_location_2=pd.DataFrame()\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "for i in range(len(ctr)):\n",
    "    overpass_query = '[out:json];' +'(' + \\\n",
    "    '// query part for: “aminity=*”' +'\\n'+\\\n",
    "    'node[\"amenity\"](around:1000,' + str(ctr[i][0])+','+str(ctr[i][1])+');'+'\\n'+\\\n",
    "    'way[\"amenity\"](around:1000,' +  str(ctr[i][0])+','+str(ctr[i][1])+');'+'\\n'+\\\n",
    "    'relation[\"amenity\"](around:1000,' +  str(ctr[i][0])+','+str(ctr[i][1])+');'+'\\n'+\\\n",
    "    ');' + '\\n'+\\\n",
    "    '// print results'+'\\n'+\\\n",
    "    'out;'+'\\n'+\\\n",
    "    '>;'+'out count;'\n",
    "     \n",
    "    response = requests.get(overpass_url, \n",
    "                        params={'data': overpass_query})\n",
    "    try:\n",
    "        data  = response.json()\n",
    "    \n",
    "    except (requests.exceptions.ConnectionError, json.decoder.JSONDecodeError):\n",
    "        time.sleep(2**1 + random.random()*0.01) #exponential backoff\n",
    "\n",
    "\n",
    "    typeamenity =[]\n",
    "    for l in range(len(data['elements'])):\n",
    "        try:\n",
    "            ind = list(data['elements'][l].keys()).index('tags')\n",
    "        \n",
    "            typeamenity.append(data['elements'][l]['tags']['amenity'])\n",
    "        except:\n",
    "            ind = False\n",
    "\n",
    "    amenity_names.append(list(Counter(typeamenity).keys()))\n",
    "    amenity_count.append(list(Counter(typeamenity).values()))\n",
    "    dictionary = dict(zip(amenity_names[i], amenity_count[i]))\n",
    "    Amenity_per_location =  pd.DataFrame.from_dict(dictionary, orient='index')\n",
    "    Amenity_per_location_2 = pd.concat([Amenity_per_location, Amenity_per_location_2], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amenity_per_location_2 = Amenity_per_location_2.T\n",
    "Amenity_per_location_2['prediction'] =np.arange(0,len(Amenity_per_location_2))\n",
    "Amenity_per_location_2.to_csv('F:/Amenity_per_location_2_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Amenity_per_location_2 = ss.read.csv(\"Amenity_per_location.csv\", header=True, sep=\",\");\n",
    "for i in range(len(year)):\n",
    "    tc_df[i] = Amenity_per_location_2.join(tc_df[i], on=['prediction'], how='right_outer')\n",
    "    tc_df[i] = tc_df[i].withColumn(\"Violation_Time\", F.concat(F.col(\"Violation_Time\"), F.lit(\"M\")))\n",
    "    tc_df[i] = tc_df[i].withColumn(\"Violation_Time\", F.to_timestamp(tc_df[i].Violation_Time, 'KKmmaa'))\n",
    "    tc_df[i] = tc_df[i].withColumn(\"Violation_Time\", F.date_format('Violation_Time', 'HH'))\n",
    "    tc_df[i] = tc_df[i].filter(tc_df[i].Violation_Time.isNotNull())\n",
    "\n",
    "#Location_with_features_1 = Amenity_per_location_2.join(transformed_1, on=['prediction'], how='right_outer')\n",
    "#Location_with_features_2 = Amenity_per_location_2.join(transformed_2, on=['prediction'], how='right_outer')\n",
    "#Location_with_features_3 = Amenity_per_location_2.join(transformed_2, on=['prediction'], how='right_outer')\n",
    "#Location_with_features_4 = Amenity_per_location_2.join(transformed_2, on=['prediction'], how='right_outer')\n",
    "#Location_with_features_5 = Amenity_per_location_2.join(transformed_2, on=['prediction'], how='right_outer')\n",
    "#Location_with_features_6 = Amenity_per_location_2.join(transformed_2, on=['prediction'], how='right_outer')\n",
    "#Location_with_features_1 = Location_with_features_1.withColumn(\"Violation_Time\", F.concat(F.col(\"Violation_Time\"), F.lit(\"M\")))\n",
    "#Location_with_features_1 = Location_with_features_1.withColumn(\"Violation_Time\", F.to_timestamp(Location_with_features_1.Violation_Time, 'KKmmaa'))\n",
    "#Location_with_features_1 = Location_with_features_1.withColumn(\"Violation_Time\", F.date_format('Violation_Time', 'HH'))\n",
    "#Location_with_features_1 = Location_with_features_1.filter(Location_with_features_1.Violation_Time.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelocation_weather = 'merged_weather_holidays_fixedMissingValues.csv'\n",
    "weather = ss.read.csv(filelocation_weather, header=True)\n",
    "weather = weather.withColumn(\"time\", F.to_timestamp(weather.time, 'HH:mm:ss'))\n",
    "weather = weather.withColumn(\"date\", F.to_timestamp(weather.date, 'yyyy-MM-dd'))\n",
    "weather = weather.withColumn(\"time\", F.date_format('time', 'HH'))\n",
    "weather = weather.withColumn(\"date\", F.date_format('date', 'MM/dd/yyyy'))\n",
    "weather = weather.withColumnRenamed(\"time\", \"Violation_Time\")\n",
    "weather = weather.withColumnRenamed(\"date\", \"Issue_Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are chosen pretty recklessly. the ones i assumed would have the least correlation to parking tickets\n",
    "\n",
    "amenities_to_drop = ['amenity|ice_cream', \n",
    "'animal_boarding', \n",
    "'animal_shelter', \n",
    "'art_centre', \n",
    "'arts_centre', \n",
    "'bicycle_parking',\n",
    "'bicycle_rental', \n",
    "'bicycle_repair_station', \n",
    "'biergarten', \n",
    "'boat_rental', \n",
    "'boat_storage',\n",
    "'car_rental', \n",
    "'car_service', \n",
    "'car_sharing',\n",
    " 'car_wash',\n",
    " 'charging_station',\n",
    " 'clock',\n",
    " 'community_centre',\n",
    " 'compressed_air',\n",
    " 'concert_hall',\n",
    " 'cooking_school',\n",
    " 'courthouse',\n",
    " 'coworking_space',\n",
    " 'dancing_school',\n",
    " 'dentist',\n",
    " 'disused',\n",
    " 'dojo',\n",
    " 'drinking_water',\n",
    " 'driving_school',\n",
    " 'ferry_terminal',\n",
    " 'fire_station',\n",
    " 'food_court',\n",
    " 'fortune_teller',\n",
    " 'fountain',\n",
    " 'fuel',\n",
    " 'graphic_design',\n",
    " 'grave_yard',\n",
    " 'ice_cream',\n",
    " 'internet_cafe',\n",
    " 'karaoke_box',\n",
    " 'language_school',\n",
    " 'library',\n",
    " 'loading_dock',\n",
    " 'meditation_centre',\n",
    " 'monastery',\n",
    " 'motorcycle_parking',\n",
    " 'museum',\n",
    " 'music_school',\n",
    " 'music_venue',\n",
    " 'nail salon',\n",
    " 'nail_salon',\n",
    " 'nursing_home',\n",
    " 'outdoor_seating',\n",
    " 'parking',\n",
    " 'parking_entrance',\n",
    " 'parking_space',\n",
    " 'payment_centre',\n",
    " 'payment_terminal', 'picnic_table',\n",
    " 'police',\n",
    " 'post_box',\n",
    " 'post_depot',\n",
    " 'prep_school',\n",
    " 'prison',\n",
    " 'public_bath',\n",
    " 'public_bookcase',\n",
    " 'public_building',\n",
    " 'radio station',\n",
    " 'ranger_station',\n",
    " 'recycling',\n",
    " 'rescue_station',\n",
    " 'research_institute',\n",
    " 'salon',\n",
    " 'self_storage',\n",
    " 'shelter',\n",
    " 'shoe_repair',\n",
    " 'smoking_area',\n",
    " 'social_centre',\n",
    " 'social_facility',\n",
    " 'spa',\n",
    " 'stock_exchange',\n",
    " 'stripclub',\n",
    " 'studio', 'swimming_pool',\n",
    " 'swingerclub',\n",
    " 'taxi',\n",
    " 'telephone',\n",
    " 'theatre',\n",
    " 'toilets',\n",
    " 'tourism',\n",
    " 'townhall',\n",
    " 'training',\n",
    " 'university',\n",
    " 'urgent_care',\n",
    " 'vehicle_inspection',\n",
    " 'vending_machine',\n",
    " 'veterinary',\n",
    " 'waste_basket',\n",
    " 'waste_disposal',\n",
    " 'waste_transfer_station',\n",
    " 'wifi;telephone;device_charging_station',\n",
    "'_c0',\n",
    "'summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#weather_locationFeatures_joined = Location_with_features_1.join(weather, (Location_with_features_1.Issue_Date == weather.date) & (Location_with_features_1.Violation_Time == weather.time))\n",
    "#weather_locationFeatures_joined = Location_with_features_1.join(weather, ['Issue_Date', 'Violation_Time'])\n",
    "merged = []\n",
    "for i in range(len(year)):\n",
    "    tc_df[i] = tc_df[i].join(weather, ['Issue_Date', 'Violation_Time'])\n",
    "    merged.append(tc_df[i].groupBy('prediction','Issue_Date','Violation_Time').count())\n",
    "    merged[i] = merged[i].join(weather, [\"Issue_Date\", \"Violation_Time\"])\n",
    "    merged[i] = merged[i].join(Amenity_per_location_2, (merged[i].prediction == Amenity_per_location_2.prediction)).drop(\"prediction\").drop(\"datetime\")\n",
    "    merged[i] = merged[i].withColumn(\"Issue_Date\", F.to_timestamp(merged[i].Issue_Date, 'MM/dd/yyyy'))\n",
    "    merged[i] = merged[i].withColumn('Day_of_week',F.dayofweek(merged[i].Issue_Date))\n",
    "    merged[i] = merged[i].withColumn('Day_of_year',F.dayofyear(merged[i].Issue_Date))\n",
    "    merged[i] = merged[i].withColumn('Day_of_month',F.dayofmonth(merged[i].Issue_Date))\n",
    "    merged[i] = merged[i].withColumn(\"Month\", F.date_format('Issue_Date', 'MM'))\n",
    "    merged[i] = merged[i].withColumn(\"Year\", F.date_format('Issue_Date', 'YYYY'))\n",
    "    merged[i] = merged[i].drop(\"Issue_Date\")\n",
    "    #for c in amenities_to_drop:\n",
    "    #    merged[i] = merged[i].drop(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'re_merge_2 = re_merge_2.withColumn(\"Issue_Date\", F.to_timestamp(re_merge_2.Issue_Date, \\'MM/dd/yyyy\\'))\\nre_merge_2 = re_merge_2.withColumn(\\'Day_of_week\\',F.dayofweek(re_merge_2.Issue_Date))\\nre_merge_2 = re_merge_2.withColumn(\\'Day_of_year\\',F.dayofyear(re_merge_2.Issue_Date))\\nre_merge_2 = re_merge_2.withColumn(\\'Day_of_month\\',F.dayofmonth(re_merge_2.Issue_Date))\\nre_merge_2 = re_merge_2.withColumn(\"Month\", F.date_format(\\'Issue_Date\\', \\'MM\\'))\\nre_merge_2 = re_merge_2.withColumn(\"Year\", F.date_format(\\'Issue_Date\\', \\'YYYY\\'))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agg = weather_locationFeatures_joined.groupBy('prediction','Issue_Date','Violation_Time').count()  \n",
    "#re_merge = agg.join(weather, [\"Issue_Date\", \"Violation_Time\"])\n",
    "#re_merge_2 = re_merge.join(Amenity_per_location_2, (re_merge.prediction == Amenity_per_location_2.prediction))\n",
    "#re_merge_2 = re_merge_2.drop(\"prediction\")\n",
    "#re_merge_2 = re_merge_2.drop(\"datetime\")\n",
    "'''re_merge_2 = re_merge_2.withColumn(\"Issue_Date\", F.to_timestamp(re_merge_2.Issue_Date, 'MM/dd/yyyy'))\n",
    "re_merge_2 = re_merge_2.withColumn('Day_of_week',F.dayofweek(re_merge_2.Issue_Date))\n",
    "re_merge_2 = re_merge_2.withColumn('Day_of_year',F.dayofyear(re_merge_2.Issue_Date))\n",
    "re_merge_2 = re_merge_2.withColumn('Day_of_month',F.dayofmonth(re_merge_2.Issue_Date))\n",
    "re_merge_2 = re_merge_2.withColumn(\"Month\", F.date_format('Issue_Date', 'MM'))\n",
    "re_merge_2 = re_merge_2.withColumn(\"Year\", F.date_format('Issue_Date', 'YYYY'))\n",
    "'''\n",
    "#re_merge_2 = re_merge_2.drop(\"Issue_Date\")\n",
    "#for c in amenities_to_drop:\n",
    "#    re_merge_2 = re_merge_2.drop(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# indexing categorical features\n",
    "\n",
    "categorical_features = [\"icon\", \"precipType\", \"summary\"] #summary (34 unique) is dropped\n",
    "\n",
    "\n",
    "for cat in categorical_features:\n",
    "    for i in range(len(year)):\n",
    "        if i == 0:\n",
    "            stringIndexer = StringIndexer(inputCol=cat, outputCol=cat+\"_cat\", stringOrderType=\"frequencyDesc\")\n",
    "            stringIndexer.setHandleInvalid(\"keep\")\n",
    "            model = stringIndexer.fit(merged[i])\n",
    "            model.setHandleInvalid(\"keep\")\n",
    "        merged[i] = model.transform(merged[i])\n",
    "        #merged[i] = merged[i].drop(\"icon\").drop(\"precipType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dropping non-indexed categorical feature columns\n",
    "for i in range(len(year)):\n",
    "    merged[i] = merged[i].drop(\"icon\").drop(\"precipType\").drop(\"summary\")\n",
    "#re_merge_2 = re_merge_2.drop(\"icon\")\n",
    "#re_merge_2 = re_merge_2.drop(\"precipType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Violation_Time: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      " |-- precipIntensity: string (nullable = true)\n",
      " |-- precipProbability: string (nullable = true)\n",
      " |-- temperature: string (nullable = true)\n",
      " |-- apparentTemperature: string (nullable = true)\n",
      " |-- dewPoint: string (nullable = true)\n",
      " |-- humidity: string (nullable = true)\n",
      " |-- pressure: string (nullable = true)\n",
      " |-- windSpeed: string (nullable = true)\n",
      " |-- windGust: string (nullable = true)\n",
      " |-- windBearing: string (nullable = true)\n",
      " |-- cloudCover: string (nullable = true)\n",
      " |-- uvIndex: string (nullable = true)\n",
      " |-- visibility: string (nullable = true)\n",
      " |-- precipAccumulation: string (nullable = true)\n",
      " |-- ozone: string (nullable = true)\n",
      " |-- Holiday: string (nullable = true)\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- amenity|ice_cream: string (nullable = true)\n",
      " |-- animal_boarding: string (nullable = true)\n",
      " |-- animal_shelter: string (nullable = true)\n",
      " |-- art_centre: string (nullable = true)\n",
      " |-- arts_centre: string (nullable = true)\n",
      " |-- atm: string (nullable = true)\n",
      " |-- bakery: string (nullable = true)\n",
      " |-- bank: string (nullable = true)\n",
      " |-- bar: string (nullable = true)\n",
      " |-- bbq: string (nullable = true)\n",
      " |-- bench: string (nullable = true)\n",
      " |-- bicycle_parking: string (nullable = true)\n",
      " |-- bicycle_rental: string (nullable = true)\n",
      " |-- bicycle_repair_station: string (nullable = true)\n",
      " |-- biergarten: string (nullable = true)\n",
      " |-- boat_rental: string (nullable = true)\n",
      " |-- boat_storage: string (nullable = true)\n",
      " |-- bureau_de_change: string (nullable = true)\n",
      " |-- bus_station: string (nullable = true)\n",
      " |-- cafe: string (nullable = true)\n",
      " |-- car_rental: string (nullable = true)\n",
      " |-- car_service: string (nullable = true)\n",
      " |-- car_sharing: string (nullable = true)\n",
      " |-- car_wash: string (nullable = true)\n",
      " |-- charging_station: string (nullable = true)\n",
      " |-- childcare: string (nullable = true)\n",
      " |-- cinema: string (nullable = true)\n",
      " |-- clinic: string (nullable = true)\n",
      " |-- clock: string (nullable = true)\n",
      " |-- clothing store: string (nullable = true)\n",
      " |-- college: string (nullable = true)\n",
      " |-- community_centre: string (nullable = true)\n",
      " |-- compressed_air: string (nullable = true)\n",
      " |-- concert_hall: string (nullable = true)\n",
      " |-- cooking_school: string (nullable = true)\n",
      " |-- courthouse: string (nullable = true)\n",
      " |-- coworking_space: string (nullable = true)\n",
      " |-- dancing_school: string (nullable = true)\n",
      " |-- dentist: string (nullable = true)\n",
      " |-- disused: string (nullable = true)\n",
      " |-- doctors: string (nullable = true)\n",
      " |-- dojo: string (nullable = true)\n",
      " |-- drinking_water: string (nullable = true)\n",
      " |-- driving_school: string (nullable = true)\n",
      " |-- embassy: string (nullable = true)\n",
      " |-- events_venue: string (nullable = true)\n",
      " |-- fast_food: string (nullable = true)\n",
      " |-- ferry_terminal: string (nullable = true)\n",
      " |-- fire_station: string (nullable = true)\n",
      " |-- food_court: string (nullable = true)\n",
      " |-- fortune_teller: string (nullable = true)\n",
      " |-- fountain: string (nullable = true)\n",
      " |-- fuel: string (nullable = true)\n",
      " |-- graphic_design: string (nullable = true)\n",
      " |-- grave_yard: string (nullable = true)\n",
      " |-- gym: string (nullable = true)\n",
      " |-- hospital: string (nullable = true)\n",
      " |-- ice_cream: string (nullable = true)\n",
      " |-- internet_cafe: string (nullable = true)\n",
      " |-- karaoke_box: string (nullable = true)\n",
      " |-- kindergarten: string (nullable = true)\n",
      " |-- language_school: string (nullable = true)\n",
      " |-- library: string (nullable = true)\n",
      " |-- loading_dock: string (nullable = true)\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- meditation_centre: string (nullable = true)\n",
      " |-- monastery: string (nullable = true)\n",
      " |-- money_transfer: string (nullable = true)\n",
      " |-- motorcycle_parking: string (nullable = true)\n",
      " |-- museum: string (nullable = true)\n",
      " |-- music_school: string (nullable = true)\n",
      " |-- music_venue: string (nullable = true)\n",
      " |-- nail salon: string (nullable = true)\n",
      " |-- nail_salon: string (nullable = true)\n",
      " |-- nightclub: string (nullable = true)\n",
      " |-- nursing_home: string (nullable = true)\n",
      " |-- outdoor_seating: string (nullable = true)\n",
      " |-- parking: string (nullable = true)\n",
      " |-- parking_entrance: string (nullable = true)\n",
      " |-- parking_space: string (nullable = true)\n",
      " |-- payment_centre: string (nullable = true)\n",
      " |-- payment_terminal: string (nullable = true)\n",
      " |-- pharmacy: string (nullable = true)\n",
      " |-- picnic_table: string (nullable = true)\n",
      " |-- place_of_worship: string (nullable = true)\n",
      " |-- police: string (nullable = true)\n",
      " |-- post_box: string (nullable = true)\n",
      " |-- post_depot: string (nullable = true)\n",
      " |-- post_office: string (nullable = true)\n",
      " |-- prep_school: string (nullable = true)\n",
      " |-- prison: string (nullable = true)\n",
      " |-- pub: string (nullable = true)\n",
      " |-- public_bath: string (nullable = true)\n",
      " |-- public_bookcase: string (nullable = true)\n",
      " |-- public_building: string (nullable = true)\n",
      " |-- radio station: string (nullable = true)\n",
      " |-- ranger_station: string (nullable = true)\n",
      " |-- recycling: string (nullable = true)\n",
      " |-- rescue_station: string (nullable = true)\n",
      " |-- research_institute: string (nullable = true)\n",
      " |-- restaurant: string (nullable = true)\n",
      " |-- salon: string (nullable = true)\n",
      " |-- school: string (nullable = true)\n",
      " |-- self_storage: string (nullable = true)\n",
      " |-- shelter: string (nullable = true)\n",
      " |-- shoe_repair: string (nullable = true)\n",
      " |-- smoking_area: string (nullable = true)\n",
      " |-- social_centre: string (nullable = true)\n",
      " |-- social_facility: string (nullable = true)\n",
      " |-- spa: string (nullable = true)\n",
      " |-- stock_exchange: string (nullable = true)\n",
      " |-- stripclub: string (nullable = true)\n",
      " |-- studio: string (nullable = true)\n",
      " |-- supermarket: string (nullable = true)\n",
      " |-- swimming_pool: string (nullable = true)\n",
      " |-- swingerclub: string (nullable = true)\n",
      " |-- taxi: string (nullable = true)\n",
      " |-- telephone: string (nullable = true)\n",
      " |-- theatre: string (nullable = true)\n",
      " |-- toilets: string (nullable = true)\n",
      " |-- tourism: string (nullable = true)\n",
      " |-- townhall: string (nullable = true)\n",
      " |-- training: string (nullable = true)\n",
      " |-- university: string (nullable = true)\n",
      " |-- urgent_care: string (nullable = true)\n",
      " |-- vehicle_inspection: string (nullable = true)\n",
      " |-- vending_machine: string (nullable = true)\n",
      " |-- veterinary: string (nullable = true)\n",
      " |-- waste_basket: string (nullable = true)\n",
      " |-- waste_disposal: string (nullable = true)\n",
      " |-- waste_transfer_station: string (nullable = true)\n",
      " |-- wifi;telephone;device_charging_station: string (nullable = true)\n",
      " |-- Day_of_week: integer (nullable = true)\n",
      " |-- Day_of_year: integer (nullable = true)\n",
      " |-- Day_of_month: integer (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- icon_cat: double (nullable = false)\n",
      " |-- precipType_cat: double (nullable = false)\n",
      " |-- summary_cat: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged[0].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Violation_Time',\n",
       " 'count',\n",
       " 'precipIntensity',\n",
       " 'precipProbability',\n",
       " 'temperature',\n",
       " 'apparentTemperature',\n",
       " 'dewPoint',\n",
       " 'humidity',\n",
       " 'pressure',\n",
       " 'windSpeed',\n",
       " 'windGust',\n",
       " 'windBearing',\n",
       " 'cloudCover',\n",
       " 'uvIndex',\n",
       " 'visibility',\n",
       " 'precipAccumulation',\n",
       " 'ozone',\n",
       " 'Holiday',\n",
       " '_c0',\n",
       " 'amenity|ice_cream',\n",
       " 'animal_boarding',\n",
       " 'animal_shelter',\n",
       " 'art_centre',\n",
       " 'arts_centre',\n",
       " 'atm',\n",
       " 'bakery',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bbq',\n",
       " 'bench',\n",
       " 'bicycle_parking',\n",
       " 'bicycle_rental',\n",
       " 'bicycle_repair_station',\n",
       " 'biergarten',\n",
       " 'boat_rental',\n",
       " 'boat_storage',\n",
       " 'bureau_de_change',\n",
       " 'bus_station',\n",
       " 'cafe',\n",
       " 'car_rental',\n",
       " 'car_service',\n",
       " 'car_sharing',\n",
       " 'car_wash',\n",
       " 'charging_station',\n",
       " 'childcare',\n",
       " 'cinema',\n",
       " 'clinic',\n",
       " 'clock',\n",
       " 'clothing store',\n",
       " 'college',\n",
       " 'community_centre',\n",
       " 'compressed_air',\n",
       " 'concert_hall',\n",
       " 'cooking_school',\n",
       " 'courthouse',\n",
       " 'coworking_space',\n",
       " 'dancing_school',\n",
       " 'dentist',\n",
       " 'disused',\n",
       " 'doctors',\n",
       " 'dojo',\n",
       " 'drinking_water',\n",
       " 'driving_school',\n",
       " 'embassy',\n",
       " 'events_venue',\n",
       " 'fast_food',\n",
       " 'ferry_terminal',\n",
       " 'fire_station',\n",
       " 'food_court',\n",
       " 'fortune_teller',\n",
       " 'fountain',\n",
       " 'fuel',\n",
       " 'graphic_design',\n",
       " 'grave_yard',\n",
       " 'gym',\n",
       " 'hospital',\n",
       " 'ice_cream',\n",
       " 'internet_cafe',\n",
       " 'karaoke_box',\n",
       " 'kindergarten',\n",
       " 'language_school',\n",
       " 'library',\n",
       " 'loading_dock',\n",
       " 'marketplace',\n",
       " 'meditation_centre',\n",
       " 'monastery',\n",
       " 'money_transfer',\n",
       " 'motorcycle_parking',\n",
       " 'museum',\n",
       " 'music_school',\n",
       " 'music_venue',\n",
       " 'nail salon',\n",
       " 'nail_salon',\n",
       " 'nightclub',\n",
       " 'nursing_home',\n",
       " 'outdoor_seating',\n",
       " 'parking',\n",
       " 'parking_entrance',\n",
       " 'parking_space',\n",
       " 'payment_centre',\n",
       " 'payment_terminal',\n",
       " 'pharmacy',\n",
       " 'picnic_table',\n",
       " 'place_of_worship',\n",
       " 'police',\n",
       " 'post_box',\n",
       " 'post_depot',\n",
       " 'post_office',\n",
       " 'prep_school',\n",
       " 'prison',\n",
       " 'pub',\n",
       " 'public_bath',\n",
       " 'public_bookcase',\n",
       " 'public_building',\n",
       " 'radio station',\n",
       " 'ranger_station',\n",
       " 'recycling',\n",
       " 'rescue_station',\n",
       " 'research_institute',\n",
       " 'restaurant',\n",
       " 'salon',\n",
       " 'school',\n",
       " 'self_storage',\n",
       " 'shelter',\n",
       " 'shoe_repair',\n",
       " 'smoking_area',\n",
       " 'social_centre',\n",
       " 'social_facility',\n",
       " 'spa',\n",
       " 'stock_exchange',\n",
       " 'stripclub',\n",
       " 'studio',\n",
       " 'supermarket',\n",
       " 'swimming_pool',\n",
       " 'swingerclub',\n",
       " 'taxi',\n",
       " 'telephone',\n",
       " 'theatre',\n",
       " 'toilets',\n",
       " 'tourism',\n",
       " 'townhall',\n",
       " 'training',\n",
       " 'university',\n",
       " 'urgent_care',\n",
       " 'vehicle_inspection',\n",
       " 'vending_machine',\n",
       " 'veterinary',\n",
       " 'waste_basket',\n",
       " 'waste_disposal',\n",
       " 'waste_transfer_station',\n",
       " 'wifi;telephone;device_charging_station',\n",
       " 'Day_of_week',\n",
       " 'Day_of_year',\n",
       " 'Day_of_month',\n",
       " 'Month',\n",
       " 'Year',\n",
       " 'icon_cat',\n",
       " 'precipType_cat',\n",
       " 'summary_cat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_features = [\"summary_cat\", \"icon_cat\", \"precipType_cat\", \"summary\", \"icon\", \"precipType\"]\n",
    "\n",
    "# the above line is commented since\n",
    "# the stringindexed categorical vars can also be float and not double\n",
    "\n",
    "cat_features = [] \n",
    "floats = [x for x in merged[0].columns if x not in cat_features]\n",
    "for i in range(len(year)):\n",
    "    for feature in floats:\n",
    "        merged[i] = merged[i].withColumn(feature, merged[i][feature].cast(types.FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2015, 2016, 2017, 2018, 2019, 2020]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+---------------+-----------------+-----------+-------------------+--------+--------+--------+---------+--------+-----------+----------+-------+----------+------------------+-----+-------+---+-----------------+---------------+--------------+----------+-----------+----+------+----+-----+---+-----+---------------+--------------+----------------------+----------+-----------+------------+----------------+-----------+-----+----------+-----------+-----------+--------+----------------+---------+------+------+-----+--------------+-------+----------------+--------------+------------+--------------+----------+---------------+--------------+-------+-------+-------+----+--------------+--------------+-------+------------+---------+--------------+------------+----------+--------------+--------+----+--------------+----------+---+--------+---------+-------------+-----------+------------+---------------+-------+------------+-----------+-----------------+---------+--------------+------------------+------+------------+-----------+----------+----------+---------+------------+---------------+-------+----------------+-------------+--------------+----------------+--------+------------+----------------+------+--------+----------+-----------+-----------+------+----+-----------+---------------+---------------+-------------+--------------+---------+--------------+------------------+----------+-----+------+------------+-------+-----------+------------+-------------+---------------+---+--------------+---------+------+-----------+-------------+-----------+----+---------+-------+-------+-------+--------+--------+----------+-----------+------------------+---------------+----------+------------+--------------+----------------------+--------------------------------------+-----------+-----------+------------+-----+------+--------+--------------+-----------+\n",
      "|Violation_Time|count|precipIntensity|precipProbability|temperature|apparentTemperature|dewPoint|humidity|pressure|windSpeed|windGust|windBearing|cloudCover|uvIndex|visibility|precipAccumulation|ozone|Holiday|_c0|amenity|ice_cream|animal_boarding|animal_shelter|art_centre|arts_centre| atm|bakery|bank|  bar|bbq|bench|bicycle_parking|bicycle_rental|bicycle_repair_station|biergarten|boat_rental|boat_storage|bureau_de_change|bus_station| cafe|car_rental|car_service|car_sharing|car_wash|charging_station|childcare|cinema|clinic|clock|clothing store|college|community_centre|compressed_air|concert_hall|cooking_school|courthouse|coworking_space|dancing_school|dentist|disused|doctors|dojo|drinking_water|driving_school|embassy|events_venue|fast_food|ferry_terminal|fire_station|food_court|fortune_teller|fountain|fuel|graphic_design|grave_yard|gym|hospital|ice_cream|internet_cafe|karaoke_box|kindergarten|language_school|library|loading_dock|marketplace|meditation_centre|monastery|money_transfer|motorcycle_parking|museum|music_school|music_venue|nail salon|nail_salon|nightclub|nursing_home|outdoor_seating|parking|parking_entrance|parking_space|payment_centre|payment_terminal|pharmacy|picnic_table|place_of_worship|police|post_box|post_depot|post_office|prep_school|prison| pub|public_bath|public_bookcase|public_building|radio station|ranger_station|recycling|rescue_station|research_institute|restaurant|salon|school|self_storage|shelter|shoe_repair|smoking_area|social_centre|social_facility|spa|stock_exchange|stripclub|studio|supermarket|swimming_pool|swingerclub|taxi|telephone|theatre|toilets|tourism|townhall|training|university|urgent_care|vehicle_inspection|vending_machine|veterinary|waste_basket|waste_disposal|waste_transfer_station|wifi;telephone;device_charging_station|Day_of_week|Day_of_year|Day_of_month|Month|  Year|icon_cat|precipType_cat|summary_cat|\n",
      "+--------------+-----+---------------+-----------------+-----------+-------------------+--------+--------+--------+---------+--------+-----------+----------+-------+----------+------------------+-----+-------+---+-----------------+---------------+--------------+----------+-----------+----+------+----+-----+---+-----+---------------+--------------+----------------------+----------+-----------+------------+----------------+-----------+-----+----------+-----------+-----------+--------+----------------+---------+------+------+-----+--------------+-------+----------------+--------------+------------+--------------+----------+---------------+--------------+-------+-------+-------+----+--------------+--------------+-------+------------+---------+--------------+------------+----------+--------------+--------+----+--------------+----------+---+--------+---------+-------------+-----------+------------+---------------+-------+------------+-----------+-----------------+---------+--------------+------------------+------+------------+-----------+----------+----------+---------+------------+---------------+-------+----------------+-------------+--------------+----------------+--------+------------+----------------+------+--------+----------+-----------+-----------+------+----+-----------+---------------+---------------+-------------+--------------+---------+--------------+------------------+----------+-----+------+------------+-------+-----------+------------+-------------+---------------+---+--------------+---------+------+-----------+-------------+-----------+----+---------+-------+-------+-------+--------+--------+----------+-----------+------------------+---------------+----------+------------+--------------+----------------------+--------------------------------------+-----------+-----------+------------+-----+------+--------+--------------+-----------+\n",
      "|           7.0|  4.0|            0.0|              0.0|      -7.17|             -11.85|  -13.28|    0.62|  1030.9|     2.77|    4.19|       10.0|       0.4|    0.0|    16.089|               0.0|  0.0|    0.0|0.0|              1.0|            0.0|           0.0|       0.0|        3.0|11.0|   0.0|31.0|107.0|0.0| 11.0|          650.0|          44.0|                   1.0|       0.0|        0.0|         0.0|             0.0|        0.0|109.0|       1.0|        0.0|        4.0|     0.0|             0.0|      2.0|   5.0|   7.0|  1.0|           0.0|    4.0|             7.0|           0.0|         0.0|           0.0|       0.0|            0.0|           1.0|    1.0|    0.0|    4.0| 2.0|          18.0|           0.0|    0.0|         1.0|     95.0|           0.0|         4.0|       1.0|           0.0|     6.0| 0.0|           0.0|       2.0|0.0|     3.0|     11.0|          0.0|        0.0|         1.0|            0.0|    5.0|         0.0|        2.0|              0.0|      0.0|           2.0|               0.0|   0.0|         1.0|        2.0|       0.0|       0.0|      7.0|         0.0|            0.0|   20.0|             3.0|          0.0|           0.0|             0.0|    19.0|         0.0|            36.0|   3.0|    17.0|       0.0|        2.0|        1.0|   0.0|18.0|        0.0|            0.0|            1.0|          0.0|           0.0|      2.0|           0.0|               0.0|     337.0|  0.0|  24.0|         0.0|    3.0|        0.0|         0.0|          0.0|            1.0|0.0|           0.0|      0.0|   1.0|        0.0|          0.0|        0.0| 0.0|      1.0|   22.0|    7.0|    0.0|     0.0|     0.0|      18.0|        0.0|               0.0|            1.0|       3.0|         5.0|           0.0|                   0.0|                                   1.0|        4.0|       14.0|        14.0|  1.0|2015.0|     5.0|           2.0|        2.0|\n",
      "|           8.0|  9.0|         0.1092|             0.36|       4.89|               4.89|     3.9|    0.93|  1016.0|     0.63|    1.62|       99.0|       1.0|    1.0|     8.477|               0.0|  0.0|    0.0|0.0|              0.0|            0.0|           0.0|       0.0|        5.0|10.0|   0.0|47.0| 65.0|0.0| 15.0|          169.0|          30.0|                   0.0|       0.0|        0.0|         0.0|             2.0|        6.0| 97.0|       4.0|        0.0|        1.0|     0.0|             1.0|      0.0|   4.0|   4.0|  2.0|           0.0|    3.0|             2.0|           0.0|         0.0|           0.0|       0.0|            1.0|           0.0|    0.0|    0.0|    0.0| 1.0|           9.0|           0.0|    0.0|         1.0|    138.0|           0.0|         6.0|       4.0|           1.0|    19.0| 1.0|           0.0|       0.0|0.0|     1.0|      5.0|          0.0|        0.0|         0.0|            0.0|    2.0|         0.0|        3.0|              0.0|      0.0|           0.0|               0.0|   0.0|         0.0|        0.0|       0.0|       1.0|      1.0|         0.0|            0.0|   39.0|             4.0|          0.0|           0.0|             0.0|    18.0|         0.0|            20.0|   4.0|    28.0|       0.0|       11.0|        0.0|   0.0|33.0|        0.0|            1.0|            0.0|          0.0|           0.0|      0.0|           0.0|               0.0|     287.0|  0.0|  11.0|         0.0|    0.0|        0.0|         0.0|          0.0|            2.0|0.0|           0.0|      7.0|   1.0|        0.0|          0.0|        0.0| 3.0|      6.0|   55.0|    6.0|    0.0|     0.0|     0.0|       4.0|        0.0|               0.0|            0.0|       0.0|         5.0|           0.0|                   0.0|                                   0.0|        6.0|      100.0|        10.0|  4.0|2015.0|     4.0|           0.0|        4.0|\n",
      "+--------------+-----+---------------+-----------------+-----------+-------------------+--------+--------+--------+---------+--------+-----------+----------+-------+----------+------------------+-----+-------+---+-----------------+---------------+--------------+----------+-----------+----+------+----+-----+---+-----+---------------+--------------+----------------------+----------+-----------+------------+----------------+-----------+-----+----------+-----------+-----------+--------+----------------+---------+------+------+-----+--------------+-------+----------------+--------------+------------+--------------+----------+---------------+--------------+-------+-------+-------+----+--------------+--------------+-------+------------+---------+--------------+------------+----------+--------------+--------+----+--------------+----------+---+--------+---------+-------------+-----------+------------+---------------+-------+------------+-----------+-----------------+---------+--------------+------------------+------+------------+-----------+----------+----------+---------+------------+---------------+-------+----------------+-------------+--------------+----------------+--------+------------+----------------+------+--------+----------+-----------+-----------+------+----+-----------+---------------+---------------+-------------+--------------+---------+--------------+------------------+----------+-----+------+------------+-------+-----------+------------+-------------+---------------+---+--------------+---------+------+-----------+-------------+-----------+----+---------+-------+-------+-------+--------+--------+----------+-----------+------------------+---------------+----------+------------+--------------+----------------------+--------------------------------------+-----------+-----------+------------+-----+------+--------+--------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged[0].show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "RANDOM_SEED = 3\n",
    "\n",
    "# in general, these should probably be pushed as far upwards as our machines can handle for better performance\n",
    "# training for 1 year with current parameters takes <10min\n",
    "\n",
    "RF_NUM_TREES = 40\n",
    "RF_MAX_DEPTH = 7\n",
    "RF_MAX_BINS = 50\n",
    "\n",
    "splits = [TRAINING_DATA_RATIO, 1.0 - TRAINING_DATA_RATIO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "training_data, test_data = [], []\n",
    "for i in  range(len(year)):\n",
    "    feature_indices = [j for j, x in enumerate(merged[i].columns) if j!=1] # all columns except the label\n",
    "    assembler = VectorAssembler(inputCols=list(np.array(merged[i].columns)[np.array(feature_indices)]),outputCol=\"features\")\\\n",
    "                .setHandleInvalid(\"keep\")\n",
    "    spDF = assembler.transform(merged[i])\n",
    "    tr, te = spDF.randomSplit(splits, RANDOM_SEED)\n",
    "    training_data.append(tr)\n",
    "    test_data.append(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data, test_data = spDF.randomSplit(splits, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training_data[0]\n",
    "test = test_data[0]\n",
    "for i in  range(1, len(year)):\n",
    "    train.union(training_data[i])\n",
    "    test.union(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=-6.920000076293945, apparentTemperature=-12.319999694824219, dewPoint=-13.890000343322754, humidity=0.5799999833106995, pressure=1010.7000122070312, windSpeed=3.490000009536743, windGust=6.21999979019165, windBearing=317.0, cloudCover=0.38999998569488525, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=0.0, animal_shelter=0.0, art_centre=0.0, arts_centre=0.0, atm=1.0, bakery=0.0, bank=3.0, bar=3.0, bbq=0.0, bench=103.0, bicycle_parking=45.0, bicycle_rental=4.0, bicycle_repair_station=0.0, biergarten=1.0, boat_rental=3.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=0.0, cafe=4.0, car_rental=1.0, car_service=0.0, car_sharing=0.0, car_wash=1.0, charging_station=0.0, childcare=2.0, cinema=1.0, clinic=1.0, clock=1.0, clothing store=0.0, college=0.0, community_centre=0.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=0.0, dancing_school=0.0, dentist=6.0, disused=0.0, doctors=3.0, dojo=0.0, drinking_water=8.0, driving_school=0.0, embassy=0.0, events_venue=0.0, fast_food=1.0, ferry_terminal=2.0, fire_station=2.0, food_court=0.0, fortune_teller=0.0, fountain=2.0, fuel=4.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=0.0, ice_cream=1.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=1.0, language_school=0.0, library=1.0, loading_dock=0.0, marketplace=0.0, meditation_centre=0.0, monastery=0.0, money_transfer=0.0, motorcycle_parking=0.0, museum=0.0, music_school=0.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=0.0, nursing_home=0.0, outdoor_seating=0.0, parking=57.0, parking_entrance=5.0, parking_space=755.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=5.0, picnic_table=0.0, place_of_worship=6.0, police=0.0, post_box=2.0, post_depot=0.0, post_office=2.0, prep_school=0.0, prison=0.0, pub=2.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=3.0, rescue_station=0.0, research_institute=0.0, restaurant=33.0, salon=0.0, school=5.0, self_storage=0.0, shelter=4.0, shoe_repair=0.0, smoking_area=0.0, social_centre=1.0, social_facility=0.0, spa=0.0, stock_exchange=0.0, stripclub=0.0, studio=1.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=0.0, theatre=0.0, toilets=3.0, tourism=0.0, townhall=0.0, training=0.0, university=1.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=6.0, veterinary=0.0, waste_basket=14.0, waste_disposal=8.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=4.0, Day_of_year=28.0, Day_of_month=28.0, Month=1.0, Year=2015.0, icon_cat=5.0, precipType_cat=2.0, summary_cat=2.0, features=SparseVector(158, {3: -6.92, 4: -12.32, 5: -13.89, 6: 0.58, 7: 1010.7, 8: 3.49, 9: 6.22, 10: 317.0, 11: 0.39, 13: 16.089, 23: 1.0, 25: 3.0, 26: 3.0, 28: 103.0, 29: 45.0, 30: 4.0, 32: 1.0, 33: 3.0, 37: 4.0, 38: 1.0, 41: 1.0, 43: 2.0, 44: 1.0, 45: 1.0, 46: 1.0, 56: 6.0, 58: 3.0, 60: 8.0, 64: 1.0, 65: 2.0, 66: 2.0, 69: 2.0, 70: 4.0, 75: 1.0, 78: 1.0, 80: 1.0, 95: 57.0, 96: 5.0, 97: 755.0, 100: 5.0, 102: 6.0, 104: 2.0, 106: 2.0, 109: 2.0, 115: 3.0, 118: 33.0, 120: 5.0, 122: 4.0, 125: 1.0, 130: 1.0, 137: 3.0, 141: 1.0, 144: 6.0, 146: 14.0, 147: 8.0, 150: 4.0, 151: 28.0, 152: 28.0, 153: 1.0, 154: 2015.0, 155: 5.0, 156: 2.0, 157: 2.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=-6.860000133514404, apparentTemperature=-13.539999961853027, dewPoint=-14.539999961853027, humidity=0.5400000214576721, pressure=1028.5999755859375, windSpeed=5.059999942779541, windGust=7.340000152587891, windBearing=338.0, cloudCover=0.3100000023841858, uvIndex=0.0, visibility=13.788000106811523, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=0.0, animal_shelter=0.0, art_centre=0.0, arts_centre=1.0, atm=8.0, bakery=0.0, bank=38.0, bar=19.0, bbq=0.0, bench=20.0, bicycle_parking=181.0, bicycle_rental=31.0, bicycle_repair_station=0.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=1.0, bus_station=1.0, cafe=67.0, car_rental=1.0, car_service=0.0, car_sharing=3.0, car_wash=0.0, charging_station=4.0, childcare=0.0, cinema=5.0, clinic=9.0, clock=1.0, clothing store=0.0, college=3.0, community_centre=1.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=0.0, dancing_school=0.0, dentist=6.0, disused=0.0, doctors=1.0, dojo=0.0, drinking_water=18.0, driving_school=0.0, embassy=0.0, events_venue=0.0, fast_food=39.0, ferry_terminal=0.0, fire_station=2.0, food_court=1.0, fortune_teller=0.0, fountain=12.0, fuel=0.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=2.0, ice_cream=0.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=0.0, language_school=0.0, library=6.0, loading_dock=0.0, marketplace=0.0, meditation_centre=0.0, monastery=0.0, money_transfer=1.0, motorcycle_parking=0.0, museum=0.0, music_school=0.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=1.0, nursing_home=0.0, outdoor_seating=0.0, parking=11.0, parking_entrance=5.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=13.0, picnic_table=0.0, place_of_worship=26.0, police=2.0, post_box=31.0, post_depot=0.0, post_office=3.0, prep_school=0.0, prison=0.0, pub=12.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=2.0, rescue_station=0.0, research_institute=0.0, restaurant=151.0, salon=0.0, school=18.0, self_storage=1.0, shelter=1.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=0.0, spa=0.0, stock_exchange=0.0, stripclub=1.0, studio=0.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=3.0, theatre=5.0, toilets=3.0, tourism=0.0, townhall=0.0, training=0.0, university=1.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=1.0, veterinary=3.0, waste_basket=37.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=6.0, Day_of_year=65.0, Day_of_month=6.0, Month=3.0, Year=2015.0, icon_cat=3.0, precipType_cat=2.0, summary_cat=0.0, features=SparseVector(158, {3: -6.86, 4: -13.54, 5: -14.54, 6: 0.54, 7: 1028.6, 8: 5.06, 9: 7.34, 10: 338.0, 11: 0.31, 13: 13.788, 22: 1.0, 23: 8.0, 25: 38.0, 26: 19.0, 28: 20.0, 29: 181.0, 30: 31.0, 35: 1.0, 36: 1.0, 37: 67.0, 38: 1.0, 40: 3.0, 42: 4.0, 44: 5.0, 45: 9.0, 46: 1.0, 48: 3.0, 49: 1.0, 56: 6.0, 58: 1.0, 60: 18.0, 64: 39.0, 66: 2.0, 67: 1.0, 69: 12.0, 74: 2.0, 80: 6.0, 85: 1.0, 92: 1.0, 95: 11.0, 96: 5.0, 100: 13.0, 102: 26.0, 103: 2.0, 104: 31.0, 106: 3.0, 109: 12.0, 115: 2.0, 118: 151.0, 120: 18.0, 121: 1.0, 122: 1.0, 129: 1.0, 135: 3.0, 136: 5.0, 137: 3.0, 141: 1.0, 144: 1.0, 145: 3.0, 146: 37.0, 150: 6.0, 151: 65.0, 152: 6.0, 153: 3.0, 154: 2015.0, 155: 3.0, 156: 2.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=-1.090000033378601, apparentTemperature=-2.9000000953674316, dewPoint=-2.75, humidity=0.8899999856948853, pressure=1020.0, windSpeed=1.440000057220459, windGust=2.8499999046325684, windBearing=29.0, cloudCover=1.0, uvIndex=0.0, visibility=4.7789998054504395, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=0.0, animal_shelter=0.0, art_centre=0.0, arts_centre=3.0, atm=15.0, bakery=0.0, bank=63.0, bar=67.0, bbq=0.0, bench=22.0, bicycle_parking=196.0, bicycle_rental=40.0, bicycle_repair_station=0.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=2.0, bus_station=2.0, cafe=120.0, car_rental=4.0, car_service=0.0, car_sharing=2.0, car_wash=0.0, charging_station=1.0, childcare=0.0, cinema=6.0, clinic=6.0, clock=2.0, clothing store=0.0, college=1.0, community_centre=1.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=0.0, dancing_school=0.0, dentist=1.0, disused=0.0, doctors=0.0, dojo=0.0, drinking_water=10.0, driving_school=0.0, embassy=1.0, events_venue=0.0, fast_food=132.0, ferry_terminal=0.0, fire_station=3.0, food_court=3.0, fortune_teller=0.0, fountain=37.0, fuel=0.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=0.0, ice_cream=6.0, internet_cafe=0.0, karaoke_box=1.0, kindergarten=0.0, language_school=0.0, library=4.0, loading_dock=0.0, marketplace=3.0, meditation_centre=0.0, monastery=0.0, money_transfer=1.0, motorcycle_parking=0.0, museum=0.0, music_school=0.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=2.0, nursing_home=0.0, outdoor_seating=0.0, parking=32.0, parking_entrance=2.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=19.0, picnic_table=0.0, place_of_worship=25.0, police=2.0, post_box=36.0, post_depot=0.0, post_office=8.0, prep_school=0.0, prison=0.0, pub=30.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=1.0, rescue_station=0.0, research_institute=0.0, restaurant=328.0, salon=0.0, school=15.0, self_storage=0.0, shelter=0.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=0.0, spa=0.0, stock_exchange=0.0, stripclub=2.0, studio=0.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=2.0, telephone=3.0, theatre=60.0, toilets=5.0, tourism=0.0, townhall=0.0, training=0.0, university=2.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=5.0, veterinary=1.0, waste_basket=10.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=7.0, Day_of_year=80.0, Day_of_month=21.0, Month=3.0, Year=2015.0, icon_cat=1.0, precipType_cat=2.0, summary_cat=1.0, features=SparseVector(158, {3: -1.09, 4: -2.9, 5: -2.75, 6: 0.89, 7: 1020.0, 8: 1.44, 9: 2.85, 10: 29.0, 11: 1.0, 13: 4.779, 22: 3.0, 23: 15.0, 25: 63.0, 26: 67.0, 28: 22.0, 29: 196.0, 30: 40.0, 35: 2.0, 36: 2.0, 37: 120.0, 38: 4.0, 40: 2.0, 42: 1.0, 44: 6.0, 45: 6.0, 46: 2.0, 48: 1.0, 49: 1.0, 56: 1.0, 60: 10.0, 62: 1.0, 64: 132.0, 66: 3.0, 67: 3.0, 69: 37.0, 75: 6.0, 77: 1.0, 80: 4.0, 82: 3.0, 85: 1.0, 92: 2.0, 95: 32.0, 96: 2.0, 100: 19.0, 102: 25.0, 103: 2.0, 104: 36.0, 106: 8.0, 109: 30.0, 115: 1.0, 118: 328.0, 120: 15.0, 129: 2.0, 134: 2.0, 135: 3.0, 136: 60.0, 137: 5.0, 141: 2.0, 144: 5.0, 145: 1.0, 146: 10.0, 150: 7.0, 151: 80.0, 152: 21.0, 153: 3.0, 154: 2015.0, 155: 1.0, 156: 2.0, 157: 1.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=2.75, apparentTemperature=2.75, dewPoint=-15.09000015258789, humidity=0.25999999046325684, pressure=1036.199951171875, windSpeed=1.0199999809265137, windGust=2.2300000190734863, windBearing=333.0, cloudCover=0.07000000029802322, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=1.0, animal_shelter=0.0, art_centre=0.0, arts_centre=4.0, atm=0.0, bakery=0.0, bank=7.0, bar=28.0, bbq=0.0, bench=3.0, bicycle_parking=10.0, bicycle_rental=0.0, bicycle_repair_station=0.0, biergarten=1.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=0.0, cafe=24.0, car_rental=0.0, car_service=0.0, car_sharing=1.0, car_wash=3.0, charging_station=0.0, childcare=1.0, cinema=0.0, clinic=2.0, clock=0.0, clothing store=0.0, college=0.0, community_centre=3.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=0.0, dancing_school=1.0, dentist=0.0, disused=0.0, doctors=3.0, dojo=2.0, drinking_water=3.0, driving_school=0.0, embassy=0.0, events_venue=3.0, fast_food=31.0, ferry_terminal=0.0, fire_station=4.0, food_court=0.0, fortune_teller=0.0, fountain=0.0, fuel=1.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=1.0, ice_cream=5.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=0.0, language_school=0.0, library=1.0, loading_dock=0.0, marketplace=4.0, meditation_centre=0.0, monastery=0.0, money_transfer=0.0, motorcycle_parking=0.0, museum=0.0, music_school=0.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=3.0, nursing_home=0.0, outdoor_seating=0.0, parking=6.0, parking_entrance=0.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=20.0, picnic_table=0.0, place_of_worship=32.0, police=0.0, post_box=18.0, post_depot=0.0, post_office=2.0, prep_school=0.0, prison=0.0, pub=2.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=0.0, rescue_station=0.0, research_institute=0.0, restaurant=124.0, salon=0.0, school=25.0, self_storage=0.0, shelter=3.0, shoe_repair=0.0, smoking_area=0.0, social_centre=2.0, social_facility=2.0, spa=0.0, stock_exchange=0.0, stripclub=0.0, studio=2.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=0.0, theatre=0.0, toilets=0.0, tourism=0.0, townhall=0.0, training=0.0, university=0.0, urgent_care=0.0, vehicle_inspection=1.0, vending_machine=0.0, veterinary=0.0, waste_basket=0.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=6.0, Day_of_year=72.0, Day_of_month=13.0, Month=3.0, Year=2015.0, icon_cat=3.0, precipType_cat=2.0, summary_cat=0.0, features=SparseVector(158, {3: 2.75, 4: 2.75, 5: -15.09, 6: 0.26, 7: 1036.2, 8: 1.02, 9: 2.23, 10: 333.0, 11: 0.07, 13: 16.089, 19: 1.0, 22: 4.0, 25: 7.0, 26: 28.0, 28: 3.0, 29: 10.0, 32: 1.0, 37: 24.0, 40: 1.0, 41: 3.0, 43: 1.0, 45: 2.0, 49: 3.0, 55: 1.0, 58: 3.0, 59: 2.0, 60: 3.0, 63: 3.0, 64: 31.0, 66: 4.0, 70: 1.0, 74: 1.0, 75: 5.0, 80: 1.0, 82: 4.0, 92: 3.0, 95: 6.0, 100: 20.0, 102: 32.0, 104: 18.0, 106: 2.0, 109: 2.0, 118: 124.0, 120: 25.0, 122: 3.0, 125: 2.0, 126: 2.0, 130: 2.0, 143: 1.0, 150: 6.0, 151: 72.0, 152: 13.0, 153: 3.0, 154: 2015.0, 155: 3.0, 156: 2.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=10.319999694824219, apparentTemperature=10.319999694824219, dewPoint=3.3299999237060547, humidity=0.6200000047683716, pressure=1018.0, windSpeed=0.9100000262260437, windGust=1.0199999809265137, windBearing=154.0, cloudCover=0.75, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=0.0, animal_shelter=0.0, art_centre=0.0, arts_centre=0.0, atm=4.0, bakery=0.0, bank=5.0, bar=8.0, bbq=0.0, bench=1.0, bicycle_parking=34.0, bicycle_rental=12.0, bicycle_repair_station=0.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=1.0, cafe=3.0, car_rental=0.0, car_service=0.0, car_sharing=0.0, car_wash=0.0, charging_station=0.0, childcare=0.0, cinema=0.0, clinic=3.0, clock=0.0, clothing store=0.0, college=0.0, community_centre=1.0, compressed_air=1.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=1.0, dancing_school=0.0, dentist=1.0, disused=0.0, doctors=2.0, dojo=0.0, drinking_water=10.0, driving_school=0.0, embassy=0.0, events_venue=0.0, fast_food=13.0, ferry_terminal=0.0, fire_station=5.0, food_court=0.0, fortune_teller=0.0, fountain=0.0, fuel=6.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=0.0, ice_cream=0.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=0.0, language_school=0.0, library=1.0, loading_dock=0.0, marketplace=0.0, meditation_centre=0.0, monastery=0.0, money_transfer=0.0, motorcycle_parking=0.0, museum=0.0, music_school=0.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=2.0, nursing_home=0.0, outdoor_seating=0.0, parking=20.0, parking_entrance=0.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=5.0, picnic_table=0.0, place_of_worship=20.0, police=2.0, post_box=11.0, post_depot=0.0, post_office=3.0, prep_school=0.0, prison=0.0, pub=1.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=0.0, rescue_station=0.0, research_institute=0.0, restaurant=21.0, salon=0.0, school=39.0, self_storage=0.0, shelter=0.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=1.0, spa=0.0, stock_exchange=0.0, stripclub=0.0, studio=12.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=1.0, telephone=1.0, theatre=0.0, toilets=1.0, tourism=0.0, townhall=0.0, training=0.0, university=0.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=1.0, veterinary=0.0, waste_basket=1.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=1.0, Day_of_year=123.0, Day_of_month=3.0, Month=5.0, Year=2015.0, icon_cat=5.0, precipType_cat=2.0, summary_cat=3.0, features=SparseVector(158, {3: 10.32, 4: 10.32, 5: 3.33, 6: 0.62, 7: 1018.0, 8: 0.91, 9: 1.02, 10: 154.0, 11: 0.75, 13: 16.089, 23: 4.0, 25: 5.0, 26: 8.0, 28: 1.0, 29: 34.0, 30: 12.0, 36: 1.0, 37: 3.0, 45: 3.0, 49: 1.0, 50: 1.0, 54: 1.0, 56: 1.0, 58: 2.0, 60: 10.0, 64: 13.0, 66: 5.0, 70: 6.0, 80: 1.0, 92: 2.0, 95: 20.0, 100: 5.0, 102: 20.0, 103: 2.0, 104: 11.0, 106: 3.0, 109: 1.0, 118: 21.0, 120: 39.0, 126: 1.0, 130: 12.0, 134: 1.0, 135: 1.0, 137: 1.0, 144: 1.0, 146: 1.0, 150: 1.0, 151: 123.0, 152: 3.0, 153: 5.0, 154: 2015.0, 155: 5.0, 156: 2.0, 157: 3.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=11.829999923706055, apparentTemperature=11.829999923706055, dewPoint=2.4100000858306885, humidity=0.5199999809265137, pressure=1025.800048828125, windSpeed=3.0899999141693115, windGust=4.570000171661377, windBearing=354.0, cloudCover=0.07999999821186066, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=0.0, animal_shelter=0.0, art_centre=0.0, arts_centre=3.0, atm=1.0, bakery=0.0, bank=8.0, bar=21.0, bbq=0.0, bench=89.0, bicycle_parking=140.0, bicycle_rental=19.0, bicycle_repair_station=0.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=2.0, cafe=26.0, car_rental=0.0, car_service=0.0, car_sharing=2.0, car_wash=0.0, charging_station=2.0, childcare=0.0, cinema=1.0, clinic=1.0, clock=0.0, clothing store=0.0, college=0.0, community_centre=6.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=0.0, dancing_school=0.0, dentist=0.0, disused=1.0, doctors=0.0, dojo=0.0, drinking_water=11.0, driving_school=0.0, embassy=0.0, events_venue=1.0, fast_food=19.0, ferry_terminal=1.0, fire_station=2.0, food_court=1.0, fortune_teller=0.0, fountain=4.0, fuel=0.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=1.0, ice_cream=4.0, internet_cafe=1.0, karaoke_box=0.0, kindergarten=2.0, language_school=0.0, library=2.0, loading_dock=0.0, marketplace=3.0, meditation_centre=0.0, monastery=0.0, money_transfer=0.0, motorcycle_parking=0.0, museum=0.0, music_school=0.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=1.0, nursing_home=0.0, outdoor_seating=0.0, parking=23.0, parking_entrance=0.0, parking_space=2.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=13.0, picnic_table=0.0, place_of_worship=15.0, police=1.0, post_box=2.0, post_depot=0.0, post_office=2.0, prep_school=0.0, prison=0.0, pub=1.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=0.0, rescue_station=0.0, research_institute=0.0, restaurant=94.0, salon=0.0, school=23.0, self_storage=0.0, shelter=0.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=1.0, spa=0.0, stock_exchange=0.0, stripclub=0.0, studio=2.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=1.0, theatre=3.0, toilets=2.0, tourism=0.0, townhall=0.0, training=0.0, university=0.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=0.0, veterinary=0.0, waste_basket=1.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=5.0, Day_of_year=134.0, Day_of_month=14.0, Month=5.0, Year=2015.0, icon_cat=3.0, precipType_cat=2.0, summary_cat=0.0, features=SparseVector(158, {3: 11.83, 4: 11.83, 5: 2.41, 6: 0.52, 7: 1025.8, 8: 3.09, 9: 4.57, 10: 354.0, 11: 0.08, 13: 16.089, 22: 3.0, 23: 1.0, 25: 8.0, 26: 21.0, 28: 89.0, 29: 140.0, 30: 19.0, 36: 2.0, 37: 26.0, 40: 2.0, 42: 2.0, 44: 1.0, 45: 1.0, 49: 6.0, 57: 1.0, 60: 11.0, 63: 1.0, 64: 19.0, 65: 1.0, 66: 2.0, 67: 1.0, 69: 4.0, 74: 1.0, 75: 4.0, 76: 1.0, 78: 2.0, 80: 2.0, 82: 3.0, 92: 1.0, 95: 23.0, 97: 2.0, 100: 13.0, 102: 15.0, 103: 1.0, 104: 2.0, 106: 2.0, 109: 1.0, 118: 94.0, 120: 23.0, 126: 1.0, 130: 2.0, 135: 1.0, 136: 3.0, 137: 2.0, 146: 1.0, 150: 5.0, 151: 134.0, 152: 14.0, 153: 5.0, 154: 2015.0, 155: 3.0, 156: 2.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=16.31999969482422, apparentTemperature=16.31999969482422, dewPoint=4.449999809265137, humidity=0.44999998807907104, pressure=1023.0999755859375, windSpeed=2.069999933242798, windGust=3.2200000286102295, windBearing=231.0, cloudCover=1.0, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=1.0, animal_shelter=0.0, art_centre=1.0, arts_centre=0.0, atm=13.0, bakery=0.0, bank=54.0, bar=67.0, bbq=0.0, bench=2.0, bicycle_parking=546.0, bicycle_rental=39.0, bicycle_repair_station=1.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=1.0, cafe=113.0, car_rental=4.0, car_service=0.0, car_sharing=4.0, car_wash=0.0, charging_station=5.0, childcare=1.0, cinema=6.0, clinic=22.0, clock=3.0, clothing store=0.0, college=5.0, community_centre=3.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=1.0, coworking_space=1.0, dancing_school=0.0, dentist=6.0, disused=1.0, doctors=6.0, dojo=2.0, drinking_water=7.0, driving_school=0.0, embassy=0.0, events_venue=0.0, fast_food=136.0, ferry_terminal=0.0, fire_station=5.0, food_court=2.0, fortune_teller=3.0, fountain=4.0, fuel=0.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=6.0, ice_cream=6.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=2.0, language_school=2.0, library=6.0, loading_dock=0.0, marketplace=1.0, meditation_centre=0.0, monastery=0.0, money_transfer=1.0, motorcycle_parking=0.0, museum=0.0, music_school=1.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=4.0, nursing_home=0.0, outdoor_seating=0.0, parking=36.0, parking_entrance=13.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=25.0, picnic_table=0.0, place_of_worship=27.0, police=3.0, post_box=36.0, post_depot=0.0, post_office=9.0, prep_school=0.0, prison=0.0, pub=19.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=3.0, rescue_station=0.0, research_institute=0.0, restaurant=337.0, salon=0.0, school=25.0, self_storage=0.0, shelter=0.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=1.0, spa=2.0, stock_exchange=0.0, stripclub=3.0, studio=2.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=5.0, theatre=11.0, toilets=4.0, tourism=0.0, townhall=0.0, training=0.0, university=21.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=0.0, veterinary=2.0, waste_basket=6.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=1.0, Day_of_week=7.0, Day_of_year=136.0, Day_of_month=16.0, Month=5.0, Year=2015.0, icon_cat=1.0, precipType_cat=2.0, summary_cat=1.0, features=SparseVector(158, {3: 16.32, 4: 16.32, 5: 4.45, 6: 0.45, 7: 1023.1, 8: 2.07, 9: 3.22, 10: 231.0, 11: 1.0, 13: 16.089, 19: 1.0, 21: 1.0, 23: 13.0, 25: 54.0, 26: 67.0, 28: 2.0, 29: 546.0, 30: 39.0, 31: 1.0, 36: 1.0, 37: 113.0, 38: 4.0, 40: 4.0, 42: 5.0, 43: 1.0, 44: 6.0, 45: 22.0, 46: 3.0, 48: 5.0, 49: 3.0, 53: 1.0, 54: 1.0, 56: 6.0, 57: 1.0, 58: 6.0, 59: 2.0, 60: 7.0, 64: 136.0, 66: 5.0, 67: 2.0, 68: 3.0, 69: 4.0, 74: 6.0, 75: 6.0, 78: 2.0, 79: 2.0, 80: 6.0, 82: 1.0, 85: 1.0, 88: 1.0, 92: 4.0, 95: 36.0, 96: 13.0, 100: 25.0, 102: 27.0, 103: 3.0, 104: 36.0, 106: 9.0, 109: 19.0, 115: 3.0, 118: 337.0, 120: 25.0, 126: 1.0, 127: 2.0, 129: 3.0, 130: 2.0, 135: 5.0, 136: 11.0, 137: 4.0, 141: 21.0, 145: 2.0, 146: 6.0, 149: 1.0, 150: 7.0, 151: 136.0, 152: 16.0, 153: 5.0, 154: 2015.0, 155: 1.0, 156: 2.0, 157: 1.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=16.31999969482422, apparentTemperature=16.31999969482422, dewPoint=4.449999809265137, humidity=0.44999998807907104, pressure=1023.0999755859375, windSpeed=2.069999933242798, windGust=3.2200000286102295, windBearing=231.0, cloudCover=1.0, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=2.0, animal_shelter=0.0, art_centre=0.0, arts_centre=2.0, atm=8.0, bakery=0.0, bank=5.0, bar=36.0, bbq=0.0, bench=97.0, bicycle_parking=232.0, bicycle_rental=20.0, bicycle_repair_station=0.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=0.0, cafe=57.0, car_rental=0.0, car_service=0.0, car_sharing=0.0, car_wash=1.0, charging_station=1.0, childcare=6.0, cinema=1.0, clinic=5.0, clock=0.0, clothing store=0.0, college=0.0, community_centre=1.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=1.0, dancing_school=2.0, dentist=13.0, disused=0.0, doctors=2.0, dojo=2.0, drinking_water=7.0, driving_school=0.0, embassy=0.0, events_venue=2.0, fast_food=52.0, ferry_terminal=0.0, fire_station=1.0, food_court=0.0, fortune_teller=2.0, fountain=2.0, fuel=2.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=1.0, ice_cream=6.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=5.0, language_school=0.0, library=3.0, loading_dock=0.0, marketplace=1.0, meditation_centre=0.0, monastery=0.0, money_transfer=2.0, motorcycle_parking=0.0, museum=0.0, music_school=1.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=1.0, nursing_home=0.0, outdoor_seating=0.0, parking=39.0, parking_entrance=0.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=7.0, picnic_table=0.0, place_of_worship=47.0, police=2.0, post_box=28.0, post_depot=0.0, post_office=3.0, prep_school=0.0, prison=0.0, pub=14.0, public_bath=0.0, public_bookcase=3.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=6.0, rescue_station=0.0, research_institute=0.0, restaurant=122.0, salon=0.0, school=19.0, self_storage=0.0, shelter=1.0, shoe_repair=0.0, smoking_area=1.0, social_centre=0.0, social_facility=4.0, spa=0.0, stock_exchange=0.0, stripclub=0.0, studio=1.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=5.0, telephone=0.0, theatre=8.0, toilets=3.0, tourism=0.0, townhall=0.0, training=0.0, university=3.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=0.0, veterinary=4.0, waste_basket=9.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=7.0, Day_of_year=136.0, Day_of_month=16.0, Month=5.0, Year=2015.0, icon_cat=1.0, precipType_cat=2.0, summary_cat=1.0, features=SparseVector(158, {3: 16.32, 4: 16.32, 5: 4.45, 6: 0.45, 7: 1023.1, 8: 2.07, 9: 3.22, 10: 231.0, 11: 1.0, 13: 16.089, 19: 2.0, 22: 2.0, 23: 8.0, 25: 5.0, 26: 36.0, 28: 97.0, 29: 232.0, 30: 20.0, 37: 57.0, 41: 1.0, 42: 1.0, 43: 6.0, 44: 1.0, 45: 5.0, 49: 1.0, 54: 1.0, 55: 2.0, 56: 13.0, 58: 2.0, 59: 2.0, 60: 7.0, 63: 2.0, 64: 52.0, 66: 1.0, 68: 2.0, 69: 2.0, 70: 2.0, 74: 1.0, 75: 6.0, 78: 5.0, 80: 3.0, 82: 1.0, 85: 2.0, 88: 1.0, 92: 1.0, 95: 39.0, 100: 7.0, 102: 47.0, 103: 2.0, 104: 28.0, 106: 3.0, 109: 14.0, 111: 3.0, 115: 6.0, 118: 122.0, 120: 19.0, 122: 1.0, 124: 1.0, 126: 4.0, 130: 1.0, 134: 5.0, 136: 8.0, 137: 3.0, 141: 3.0, 145: 4.0, 146: 9.0, 150: 7.0, 151: 136.0, 152: 16.0, 153: 5.0, 154: 2015.0, 155: 1.0, 156: 2.0, 157: 1.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.0, precipProbability=0.0, temperature=21.049999237060547, apparentTemperature=21.049999237060547, dewPoint=13.229999542236328, humidity=0.6100000143051147, pressure=1010.4000244140625, windSpeed=3.359999895095825, windGust=7.079999923706055, windBearing=336.0, cloudCover=0.3400000035762787, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=0.0, animal_shelter=0.0, art_centre=0.0, arts_centre=5.0, atm=9.0, bakery=0.0, bank=14.0, bar=10.0, bbq=2.0, bench=89.0, bicycle_parking=169.0, bicycle_rental=12.0, bicycle_repair_station=0.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=0.0, cafe=32.0, car_rental=0.0, car_service=0.0, car_sharing=3.0, car_wash=0.0, charging_station=1.0, childcare=3.0, cinema=1.0, clinic=5.0, clock=0.0, clothing store=0.0, college=0.0, community_centre=1.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=0.0, coworking_space=0.0, dancing_school=0.0, dentist=1.0, disused=0.0, doctors=2.0, dojo=2.0, drinking_water=39.0, driving_school=0.0, embassy=0.0, events_venue=0.0, fast_food=35.0, ferry_terminal=0.0, fire_station=2.0, food_court=0.0, fortune_teller=0.0, fountain=7.0, fuel=2.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=2.0, ice_cream=1.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=1.0, language_school=0.0, library=2.0, loading_dock=0.0, marketplace=0.0, meditation_centre=0.0, monastery=0.0, money_transfer=0.0, motorcycle_parking=0.0, museum=0.0, music_school=1.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=0.0, nursing_home=0.0, outdoor_seating=0.0, parking=28.0, parking_entrance=11.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=20.0, picnic_table=0.0, place_of_worship=21.0, police=2.0, post_box=31.0, post_depot=0.0, post_office=3.0, prep_school=0.0, prison=0.0, pub=3.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=1.0, recycling=10.0, rescue_station=0.0, research_institute=0.0, restaurant=95.0, salon=0.0, school=24.0, self_storage=0.0, shelter=0.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=3.0, spa=0.0, stock_exchange=0.0, stripclub=0.0, studio=0.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=8.0, theatre=0.0, toilets=10.0, tourism=0.0, townhall=0.0, training=0.0, university=0.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=1.0, veterinary=2.0, waste_basket=36.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=0.0, Day_of_week=4.0, Day_of_year=140.0, Day_of_month=20.0, Month=5.0, Year=2015.0, icon_cat=5.0, precipType_cat=2.0, summary_cat=2.0, features=SparseVector(158, {3: 21.05, 4: 21.05, 5: 13.23, 6: 0.61, 7: 1010.4, 8: 3.36, 9: 7.08, 10: 336.0, 11: 0.34, 13: 16.089, 22: 5.0, 23: 9.0, 25: 14.0, 26: 10.0, 27: 2.0, 28: 89.0, 29: 169.0, 30: 12.0, 37: 32.0, 40: 3.0, 42: 1.0, 43: 3.0, 44: 1.0, 45: 5.0, 49: 1.0, 56: 1.0, 58: 2.0, 59: 2.0, 60: 39.0, 64: 35.0, 66: 2.0, 69: 7.0, 70: 2.0, 74: 2.0, 75: 1.0, 78: 1.0, 80: 2.0, 88: 1.0, 95: 28.0, 96: 11.0, 100: 20.0, 102: 21.0, 103: 2.0, 104: 31.0, 106: 3.0, 109: 3.0, 114: 1.0, 115: 10.0, 118: 95.0, 120: 24.0, 126: 3.0, 135: 8.0, 137: 10.0, 144: 1.0, 145: 2.0, 146: 36.0, 150: 4.0, 151: 140.0, 152: 20.0, 153: 5.0, 154: 2015.0, 155: 5.0, 156: 2.0, 157: 2.0})),\n",
       " Row(Violation_Time=0.0, count=1.0, precipIntensity=0.009100000374019146, precipProbability=0.009999999776482582, temperature=22.729999542236328, apparentTemperature=22.889999389648438, dewPoint=17.010000228881836, humidity=0.699999988079071, pressure=1014.0, windSpeed=1.1299999952316284, windGust=2.859999895095825, windBearing=322.0, cloudCover=0.03999999910593033, uvIndex=0.0, visibility=16.089000701904297, precipAccumulation=0.0, ozone=0.0, Holiday=0.0, _c0=0.0, amenity|ice_cream=0.0, animal_boarding=1.0, animal_shelter=0.0, art_centre=0.0, arts_centre=1.0, atm=11.0, bakery=0.0, bank=42.0, bar=67.0, bbq=0.0, bench=50.0, bicycle_parking=483.0, bicycle_rental=40.0, bicycle_repair_station=1.0, biergarten=0.0, boat_rental=0.0, boat_storage=0.0, bureau_de_change=0.0, bus_station=0.0, cafe=90.0, car_rental=2.0, car_service=0.0, car_sharing=4.0, car_wash=0.0, charging_station=2.0, childcare=2.0, cinema=5.0, clinic=15.0, clock=3.0, clothing store=0.0, college=4.0, community_centre=2.0, compressed_air=0.0, concert_hall=0.0, cooking_school=0.0, courthouse=1.0, coworking_space=0.0, dancing_school=0.0, dentist=4.0, disused=0.0, doctors=4.0, dojo=2.0, drinking_water=10.0, driving_school=0.0, embassy=0.0, events_venue=0.0, fast_food=118.0, ferry_terminal=1.0, fire_station=4.0, food_court=1.0, fortune_teller=2.0, fountain=5.0, fuel=1.0, graphic_design=0.0, grave_yard=0.0, gym=0.0, hospital=7.0, ice_cream=9.0, internet_cafe=0.0, karaoke_box=0.0, kindergarten=2.0, language_school=0.0, library=5.0, loading_dock=0.0, marketplace=1.0, meditation_centre=0.0, monastery=0.0, money_transfer=1.0, motorcycle_parking=0.0, museum=0.0, music_school=1.0, music_venue=0.0, nail salon=0.0, nail_salon=0.0, nightclub=3.0, nursing_home=0.0, outdoor_seating=0.0, parking=30.0, parking_entrance=10.0, parking_space=0.0, payment_centre=0.0, payment_terminal=0.0, pharmacy=18.0, picnic_table=0.0, place_of_worship=29.0, police=1.0, post_box=25.0, post_depot=0.0, post_office=5.0, prep_school=1.0, prison=0.0, pub=18.0, public_bath=0.0, public_bookcase=0.0, public_building=0.0, radio station=0.0, ranger_station=0.0, recycling=4.0, rescue_station=0.0, research_institute=0.0, restaurant=279.0, salon=0.0, school=22.0, self_storage=0.0, shelter=2.0, shoe_repair=0.0, smoking_area=0.0, social_centre=0.0, social_facility=0.0, spa=1.0, stock_exchange=0.0, stripclub=0.0, studio=1.0, supermarket=0.0, swimming_pool=0.0, swingerclub=0.0, taxi=0.0, telephone=1.0, theatre=15.0, toilets=4.0, tourism=0.0, townhall=0.0, training=0.0, university=15.0, urgent_care=0.0, vehicle_inspection=0.0, vending_machine=1.0, veterinary=3.0, waste_basket=19.0, waste_disposal=0.0, waste_transfer_station=0.0, wifi;telephone;device_charging_station=1.0, Day_of_week=4.0, Day_of_year=168.0, Day_of_month=17.0, Month=6.0, Year=2015.0, icon_cat=3.0, precipType_cat=0.0, summary_cat=0.0, features=SparseVector(158, {1: 0.0091, 2: 0.01, 3: 22.73, 4: 22.89, 5: 17.01, 6: 0.7, 7: 1014.0, 8: 1.13, 9: 2.86, 10: 322.0, 11: 0.04, 13: 16.089, 19: 1.0, 22: 1.0, 23: 11.0, 25: 42.0, 26: 67.0, 28: 50.0, 29: 483.0, 30: 40.0, 31: 1.0, 37: 90.0, 38: 2.0, 40: 4.0, 42: 2.0, 43: 2.0, 44: 5.0, 45: 15.0, 46: 3.0, 48: 4.0, 49: 2.0, 53: 1.0, 56: 4.0, 58: 4.0, 59: 2.0, 60: 10.0, 64: 118.0, 65: 1.0, 66: 4.0, 67: 1.0, 68: 2.0, 69: 5.0, 70: 1.0, 74: 7.0, 75: 9.0, 78: 2.0, 80: 5.0, 82: 1.0, 85: 1.0, 88: 1.0, 92: 3.0, 95: 30.0, 96: 10.0, 100: 18.0, 102: 29.0, 103: 1.0, 104: 25.0, 106: 5.0, 107: 1.0, 109: 18.0, 115: 4.0, 118: 279.0, 120: 22.0, 122: 2.0, 127: 1.0, 130: 1.0, 135: 1.0, 136: 15.0, 137: 4.0, 141: 15.0, 144: 1.0, 145: 3.0, 146: 19.0, 149: 1.0, 150: 4.0, 151: 168.0, 152: 17.0, 153: 6.0, 154: 2015.0, 155: 3.0}))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o17731.fit.\n: org.apache.spark.SparkException: Job 76 cancelled because SparkContext was shut down\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:956)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:954)\r\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\r\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:954)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2221)\r\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\r\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2134)\r\n\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:1967)\r\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)\r\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1967)\r\n\tat org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:626)\r\n\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\r\n\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1423)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1396)\r\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:119)\r\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:274)\r\n\tat org.apache.spark.ml.regression.RandomForestRegressor.$anonfun$train$1(RandomForestRegressor.scala:150)\r\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\r\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:134)\r\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:43)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:114)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o17731.fit.\n: org.apache.spark.SparkException: Job 76 cancelled because SparkContext was shut down\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:956)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:954)\r\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\r\n\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:954)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2221)\r\n\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\r\n\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2134)\r\n\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:1967)\r\n\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)\r\n\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1967)\r\n\tat org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:626)\r\n\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\r\n\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1423)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1396)\r\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:119)\r\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:274)\r\n\tat org.apache.spark.ml.regression.RandomForestRegressor.$anonfun$train$1(RandomForestRegressor.scala:150)\r\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\r\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:134)\r\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:43)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:114)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(numTrees=RF_NUM_TREES, maxDepth=RF_MAX_DEPTH, labelCol='count')\n",
    "rf.setSeed(3)\n",
    "model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StringIndexerModel' object has no attribute 'featureImportances'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8f63f556c46c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatureImp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatureImportances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'StringIndexerModel' object has no attribute 'featureImportances'"
     ]
    }
   ],
   "source": [
    "featureImp = model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ExtractFeatureImp(featureImp, train, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores.to_csv('rf_scores_whole_dataset_50_trees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"count\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#model_name = \"RF_DF_second\"\n",
    "#model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing writing and reading the df to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(year)):\n",
    "    merged[i].write.csv(str('merged'+str(i)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = ss.read.csv('re_merge_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_count = train.agg(F.avg(F.col(\"count\")))\n",
    "mean_count = mean_count.take(1)\n",
    "mean_count = mean_count[0][0]\n",
    "mean_count = int(mean_count)\n",
    "print('The mean number of ticket per hour per location is: ' + str(mean_count))\n",
    "test_2 = test.withColumn('avg_count', F.lit(mean_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_2 = test_2.withColumn('avg_count', test_2['avg_count'].cast(types.DoubleType()))\n",
    "test_2 = test_2.withColumn('count', test_2['count'].cast(types.DoubleType()))\n",
    "baseline = test_2.select(['avg_count','count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"avg_count\", predictionCol=\"count\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(baseline)\n",
    "print('RMSE: '+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"avg_count\", predictionCol=\"count\", metricName=\"mae\")\n",
    "mae = evaluator_mae.evaluate(baseline)\n",
    "print('MAE: '+str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(maxIter=10, maxDepth=5, labelCol=\"count\", seed=42,\n",
    "    leafCol=\"leafId\")\n",
    "model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImp = model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ExtractFeatureImp(featureImp, train, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores.to_csv('gbt_scores_whole_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"count\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 53975)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pc\\Anaconda3\\envs\\sddm\\lib\\socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"C:\\Users\\pc\\Anaconda3\\envs\\sddm\\lib\\socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Users\\pc\\Anaconda3\\envs\\sddm\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Users\\pc\\Anaconda3\\envs\\sddm\\lib\\socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"C:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"C:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"C:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"C:\\spark\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\serializers.py\", line 593, in read_int\n",
      "    length = stream.read(4)\n",
      "  File \"C:\\Users\\pc\\Anaconda3\\envs\\sddm\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "ss.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
